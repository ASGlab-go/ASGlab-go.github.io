
@article{ WOS:001453235500001,
Author = {Zhong, Jian and Chen, Chen and Zhang, Haochen and Shen, Wentao and Fan,
   Zhong and Qiu, Dawei and Bie, Zhaohong},
Title = {Resilient mobile energy storage resources-based microgrid formation
   considering power-transportation-information network interdependencies},
Journal = {APPLIED ENERGY},
Year = {2025},
Volume = {389},
Month = {JUL 1},
Abstract = {The advancement of smart city technologies has deepened the interactions
   among power, transportation, and information networks (PTINs). Current
   mobile energy storage resource (MESR) based power distribution network
   (PDN) restoration schemes often overlook the interdependencies among
   PTINs, thus hindering efficient load restoration. This paper outlines
   the key interacting factors within PTINs, including power supply demand,
   traffic efficiency, communication coverage, electric vehicle (EV)
   deployment capability, and PDN controllability. We further develop a
   PTIN-interacting model to demonstrate the `chained recovery effect' in
   MESR-based restoration. Building on this, we propose a rolling
   optimization load restoration scheme utilizing EVs, mobile energy
   storage systems (MESSs), and unmanned aerial vehicles (UAVs), to restore
   the power supply to loads. The algorithm optimizes the load restoration
   schemes by evaluating the criticality of power loads, transportation,
   and communication nodes and their interdependencies. It further
   dynamically recalculates subsequent restoration schemes based on the
   varying states of PTINs during extreme events and the recovery impacts
   of prior operations on the PTINs, using a rolling horizon. This approach
   adapts to changing conditions, improving load restoration, enhancing the
   solution's adaptability to uncertainties during the restoration process,
   and increasing its practicality. Additionally, a PTIN-integrated
   co-simulation platform is developed to verify the effectiveness of the
   restoration methods. Case studies conducted on the platform show
   significant improvements in both the restored load capacity and
   restoration speed of the proposed scheme.},
DOI = {10.1016/j.apenergy.2025.125716},
Article-Number = {125716},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Zhong, Jian/MGA-3637-2025},
ORCID-Numbers = {Zhong, Jian/0000-0001-5406-9159},
Unique-ID = {WOS:001453235500001},
}

@article{ WOS:001470908800001,
Author = {Wang, Junkai and Qiu, Dawei and Wang, Yi and Ye, Yujian and Strbac,
   Goran},
Title = {Investigating the impact of demand-side flexibility on market-driven
   generation planning toward a fully decarbonized power system},
Journal = {ENERGY},
Year = {2025},
Volume = {324},
Month = {JUN 1},
Abstract = {The power system is undergoing a historic transition toward 100\%
   renewable energy, posing significant challenges to operation of
   conventional power systems and energy markets due to the intermittency
   of renewable sources. In this context, flexible resources are being
   deployed to address these challenges, yet their market viability remains
   underexplored. This paper fills that gap by developing a bi-level
   optimization framework to assess the impact of flexibility on generation
   planning in energy markets. The upper-level problem models the
   profit-driven planning problem of the generation company, while the
   lower-level problems represent market clearing processes: one for
   day-ahead and real-time markets with carbon constraints, and another for
   the green certificate market. To account for uncertainties in demand and
   renewable generation, a chance-constrained approach is adopted,
   reformulated as a second-order conic program for tractability. The model
   is then transformed into a single-level mathematical program with
   equilibrium constraints using Karush-Kuhn-Tucker conditions and further
   recast as a mixed-integer quadratic program. There is a fourfold scope
   in terms of the examined case studies. First, they assess the benefits
   of demand flexibility within a deregulated market environment in terms
   of mitigating the massive renewable uncertainty. Second, they highlight
   the significant value of energy storage systems in integrating
   substantial renewable generation and guaranteeing stable system
   operation. Third, they rigorously validate the high levels of demand
   flexibility, in conjunction with the utility-scale energy storage
   systems, which not only ensure the stable operation of a 100\% renewable
   power system but also guarantee adequate economic benefits. Finally,
   they demonstrate how flexibility resources play distinct roles in
   traditional and fully decarbonized power systems, and how they affect
   their respective business cases.},
DOI = {10.1016/j.energy.2025.135692},
Article-Number = {135692},
ISSN = {0360-5442},
EISSN = {1873-6785},
ResearcherID-Numbers = {Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089
   Ye, Yujian/0000-0002-9278-9218
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:001470908800001},
}

@article{ WOS:001473555800015,
Author = {Qiu, Dawei and Wang, Jianhong and Ruan, Guangchun and Zhang, Qianzhi and
   Strbac, Goran},
Title = {Robust Reinforcement Learning for Decision Making Under Uncertainty in
   Electricity Markets},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2025},
Volume = {40},
Number = {3},
Pages = {2750-2763},
Month = {MAY},
Abstract = {Reinforcement learning (RL) is a powerful tool for market agents solving
   decision-making problems in electricity markets. Vanilla RL enables
   agents to learn optimal policies in dynamic and uncertain market
   environments via trial and error. However, uncertainties in state
   transitions are often treated as exogenous state features with
   statistical errors. This approach can result in policies that are
   sensitive to perturbations of these uncertainties, potentially leading
   to performance degradation. This sensitivity is particularly critical in
   electricity markets, where the penetration of renewable energy and
   demand variability are increasing. To address this issue, this paper
   proposes a robust adversarial RL algorithm aimed at learning a robust
   optimal policy that accounts for market uncertainties in state
   transitions to systematically mitigate sensitivity to perturbations in
   uncertain environments. Specifically, we leverage the uncertainty set
   regularizer technique to define uncertainty sets within the parametric
   space of state transitions. Furthermore, we introduce a novel
   adversarial approach to generate unknown uncertainty sets using the
   value function as a basis. We finally conduct a comprehensive assessment
   of the robust adversarial RL algorithm across three electricity market
   applications: strategic bidding, retail pricing, and peer-to-peer energy
   trading, demonstrating significant improvements in robustness
   performance against various uncertainties.},
DOI = {10.1109/TPWRS.2024.3502639},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Zhang, Qianzhi/AIC-9527-2022
   Ruan, Guangchun (Grant)/AAX-5127-2020
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001473555800015},
}

@article{ WOS:001473151200018,
Author = {Sun, Xiaotian and Xie, Haipeng and Qiu, Dawei and Xiao, Yunpeng and
   Strbac, Goran and Bie, Zhaohong},
Title = {Learning the Reluctance of Demand-Side Resources From Equilibrium in
   Price-Based Demand Response},
Journal = {IEEE TRANSACTIONS ON SMART GRID},
Year = {2025},
Volume = {16},
Number = {3},
Pages = {2699-2702},
Month = {MAY},
Abstract = {The reluctance of demand-side resources (DSRs) in demand response (DR)
   is not directly accessible, yet, significantly impacts the DR
   performance. This work aims to estimate DR reluctance from observed DR
   equilibrium outcomes by inverse variational inequality (VI). First, the
   definition and properties of DR reluctance are introduced. Then, the
   equivalent generalized Nash equilibrium condition in DR is derived by
   strong duality. Based on inverse VI technique, a data-driven
   linear-programming (LP) for learning DR reluctance is formulated.
   Finally, the proposed method is validated through a toy example and
   larger-scale cases, showing its effectiveness and scalability.},
DOI = {10.1109/TSG.2025.3546799},
ISSN = {1949-3053},
EISSN = {1949-3061},
ResearcherID-Numbers = {Sun, Xiaotian/GSO-1850-2022
   Xie, Haipeng/HNP-8356-2023},
Unique-ID = {WOS:001473151200018},
}

@article{ WOS:001458668100001,
Author = {Zhang, Haoyang and Qiu, Dawei and Kok, Koen and Paterakis, Nikolaos G.},
Title = {Reliability assessment of multi-agent reinforcement learning algorithms
   for hybrid local electricity market simulation},
Journal = {APPLIED ENERGY},
Year = {2025},
Volume = {389},
Month = {JUL 1},
Abstract = {The reliability of data-driven multi-agent reinforcement learning (MARL)
   algorithms is a critical concern, particularly for complex, large-scale
   multi-agent decision-making problems. This paper aims to assess the
   reliability of various MARL algorithms in supporting decision-making for
   prosumer participants in a hybrid local electricity market (LEM) that
   combines community-based markets and a peer-to-peer (P2P) market.
   Specifically, it compares the performance of three MARL algorithms: the
   multi-agent deep deterministic policy gradient (MADDPG) algorithm and
   two advanced variants incorporating mean-field approximation and
   attention mechanisms. To evaluate the reliability of these data-driven
   MARL algorithms, a model-based bi-level optimization problem is
   introduced for each agent to assess convergence speed and the proximity
   of results to the epsilon-Nash equilibrium, as indicated by the
   no-regret index. The no-regret index is calculated within a mathematical
   program with equilibrium constraints (MPEC) by fixing the other agents'
   behavior generated from the MARL algorithms. Simulation results
   demonstrate that the attention-MADDPG algorithm achieves the highest
   no-regret index (0.81), indicating convergence closest to equilibrium,
   and the greatest total cost reduction (983(sic)), outperforming the
   other MARL algorithms. The meanfield-MADDPG algorithm is the most
   balanced, exhibiting robust convergence with the second-highest
   no-regret index (0.78) and cost reduction (958.8(sic)) under the lowest
   computational burden (5.4 seconds per episode).},
DOI = {10.1016/j.apenergy.2025.125789},
EarlyAccessDate = {MAR 2025},
Article-Number = {125789},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Paterakis, Nikolaos/F-9072-2015},
Unique-ID = {WOS:001458668100001},
}

@article{ WOS:001457872000001,
Author = {Ye, Zhian and Qiu, Dawei and Li, Shuangqi and Fan, Zhong and Strbac,
   Goran},
Title = {Federated Reinforcement Learning for decentralized peer-to-peer energy
   trading},
Journal = {ENERGY AND AI},
Year = {2025},
Volume = {20},
Month = {MAY},
Abstract = {The rapid development of distributed energy resources has led to an
   increasing number of prosumers enhancing their energy utilization,
   thereby raising the demands on energy management technologies. As a
   result, the development of future smart grids is becoming increasingly
   important, with a particular emphasis on integrating demand-side
   flexibility into electricity market. To facilitate distributed
   interaction among prosumers, the double-side auction market enables
   peer-to-peer (P2P) energy trading, maximizing the social welfare within
   the dynamic local electricity market. In this setup, prosumers can set
   their own bidding prices and optimize their operations and trading
   strategies. However, trading in double-side auction market faces
   limitations due to the complexity of the market clearing algorithm and
   the difficulty of predicting other participants' bidding behaviors. To
   address these challenges, this paper models the P2P energy trading
   problem in the double-side auction market as a multi-agent reinforcement
   learning (MARL) task. The concept of federated learning is introduced to
   enhance scalability among market participants while protecting the
   private information of individual prosumers. Additionally, the
   parameter-sharing framework is proposed to accelerate the learning
   process. To further improve the stability of MARL training, the global
   information of P2P energy},
DOI = {10.1016/j.egyai.2025.100500},
EarlyAccessDate = {MAR 2025},
Article-Number = {100500},
ISSN = {2666-5468},
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001457872000001},
}

@article{ WOS:001355530500001,
Author = {Ma, Qiaoyu and Fu, Xueqian and Yang, Qiang and Qiu, Dawei},
Title = {Adaptive masked network for ultra-short-term photovoltaic forecast},
Journal = {ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE},
Year = {2025},
Volume = {139},
Number = {B},
Month = {JAN},
Abstract = {In recent years, power grid companies have faced increasingly stringent
   requirements for accurate prediction of photovoltaic (PV) power
   generation with the rapid development of PV technologies. In
   ultra-short-term forecasting, PV power generation exhibits strong
   temporal correlations, leading to high data redundancy. To address this
   issue, we propose an adaptive masked network (ASMNet) to enhance the
   accuracy of ultra-shortterm PV forecasting. Specifically, this method
   improves the feature extraction of short-term fluctuations within
   historical time periods by down-weighting less significant temporal
   segments during the learning process. It captures the uncertain effects
   of environmental changes and provides abetter understanding of the
   impacts of ultra-short-term fluctuations. We test our model on three
   public PV power generation datasets, and it achieves the best
   performance with a root mean square error of 21.42, 0.2824 and 23.36 for
   the Belgian, American National Renewable Energy Laboratory, and Desert
   Knowledge Australia Solar Center datasets, respectively. Additionally,
   the proposed model demonstrates a 0.01\%-0.50\% improvement in
   coefficient of determination compared to baseline models across all
   datasets, highlighting its superior performance and effectiveness in
   ultra-short-term PV forecasting.},
DOI = {10.1016/j.engappai.2024.109555},
EarlyAccessDate = {NOV 2024},
Article-Number = {109555},
ISSN = {0952-1976},
EISSN = {1873-6769},
ResearcherID-Numbers = {Fu, Xueqian/Y-3381-2019
   },
ORCID-Numbers = {Fu, Xueqian/0000-0001-7983-8700},
Unique-ID = {WOS:001355530500001},
}

@article{ WOS:001354004100001,
Author = {Xiong, Zhan and Zhang, Chunyan and Qiu, Dawei and Wang, Lingling and
   Jiang, Chuanwen and Zhou, Shichao},
Title = {Feasible region identification approach for the regional integrated
   energy system considering flexible ramping constraints based on
   polyhedral projection algorithm},
Journal = {INTERNATIONAL JOURNAL OF ELECTRICAL POWER \& ENERGY SYSTEMS},
Year = {2024},
Volume = {163},
Month = {DEC},
Abstract = {The low-carbon agenda promotes the increasing penetration of renewable
   energy, this however also results in a rapid decrease in the flexibility
   of power systems with less controllable generation. There is an urgent
   requirement to explore user-side resources to provide flexibility for
   the power system. The regional integrated energy system (RIES) contains
   a large number of multi-energy coupling devices with abundant
   flexibility. However, considering the multi-energy complementary
   characteristics and complex multi-energy networks, as well as the
   uncertainty of the renewable energy, it is difficult to quantify the
   energy purchasing demand and flexibility support ability of RIES in the
   market, making it challenging to identify the RIES feasible region. This
   paper proposes a novel approach to tackle this challenge by introducing
   a projection method based on secondorder cone programming. The approach
   aims to describe the energy purchasing and flexible reserve feasible
   regions of an RIES. Specifically, a max-min RIES operating model is
   constructed with the goal of minimizing the distance from the boundary
   of the feasible region in the worst case. Subsequently, the strong
   duality principle and Karush-Kuhn-Tucker (KKT) optimality conditions are
   leveraged to reformulate the max-min optimization problem into a
   solvable second-order cone programming problem. Additionally, the chance
   constraint is introduced to address and express the risk associated the
   uncertainty of the renewable energy output in RIES. Moreover, for the
   convenience of subsequent solving, the deterministic equivalent method
   is used to convert it into a deterministic constraint. Case studies
   conducted on an RIES incorporating a 33-bus distribution network and a
   7-node natural gas network demonstrate the effectiveness and efficiency
   of the proposed approach in projecting the feasible region in terms of
   both operating costs and computational time.},
DOI = {10.1016/j.ijepes.2024.110347},
EarlyAccessDate = {NOV 2024},
Article-Number = {110347},
ISSN = {0142-0615},
EISSN = {1879-3517},
ResearcherID-Numbers = {WANG, Lingling/ABH-9973-2020
   xiong, grace/KVY-6142-2024
   Zhang, Chunyan/JAC-8767-2023},
Unique-ID = {WOS:001354004100001},
}

@article{ WOS:001352721500001,
Author = {Wang, Jiawei and Wang, Yi and Qiu, Dawei and Su, Hanguang and Strbac,
   Goran and Gao, Zhiwei},
Title = {Resilient energy management of a multi-energy building under
   low-temperature district heating: A deep reinforcement learning approach},
Journal = {APPLIED ENERGY},
Year = {2025},
Volume = {378},
Number = {A},
Month = {JAN 15},
Abstract = {The corrective control of a building-level multi-energy system (MES) for
   emergency load shedding is essential to optimize the operating cost
   after contingency. Fora Danish case, the heating devices in the building
   are connected to a developing low-temperature district heating (LTDH)
   system and operated under a heat market. Due to the coupling between the
   electrical power and heating system, an electricity outage can be
   propagated to the heating network, and heat prices as well as tariffs
   can impact the MES operating cost. In the previous studies, only
   electrical load shedding is modeled, while the impact of electricity
   outages on heating system operation and heat load control is ignored. On
   the other hand, the problem is traditionally solved by model- based
   optimization methods which are highly nonconvex leading to high
   computing complexity. Moreover, operating uncertainties can lead to
   infeasible solutions. To address these challenges, this paper proposes a
   deep reinforcement learning-based corrective control method for the
   resilient energy management of a building-level MES. In the method, the
   proximal policy optimization algorithm is applied, where multiple
   uncertainties, system dynamics, and operating constraints are
   considered. A case study of a real-life residential building connected
   to the LTDH system in Denmark is carried out, where electricity outages
   are simulated. The results verify the performance of the proposed method
   in achieving resilient energy management of the MES.},
DOI = {10.1016/j.apenergy.2024.124780},
EarlyAccessDate = {NOV 2024},
Article-Number = {124780},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Su, Hanguang/LYO-9251-2024
   Wang, Yi/JED-9446-2023
   Wang, Jiawei/HMO-9885-2023},
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Wang, Jiawei/0000-0002-1891-0657},
Unique-ID = {WOS:001352721500001},
}

@article{ WOS:001362604800017,
Author = {Qiu, Dawei and Strbac, Goran and Wang, Yi and Ye, Yujian and Wang,
   Jiawei and Pinson, Pierre and Silva, Vera and Teng, Fei},
Title = {Artificial Intelligence for Microgrid Resilience: A Data-Driven and
   Model-Free Approach},
Journal = {IEEE POWER \& ENERGY MAGAZINE},
Year = {2024},
Volume = {22},
Number = {6},
Pages = {18-27},
Month = {NOV},
Abstract = {Extreme weather events, which are characterized by high impact and low
   probability, can disrupt power system components and lead to severe
   power outages. The increasing adoption of renewable energy resources in
   the power sector, as part of decarbonization efforts, introduces further
   system operation challenges because of their fluctuating nature,
   potentially worsening the impact of these extreme weather events. To
   address the challenges from these high-impact and low-probability
   events, the concept of resilience has been introduced into the power
   industry. Considering the potential serious disruptions, the primary
   goal of resilient power system operation during extreme events is to
   ensure the continuous supply of critical loads, such as hospitals,
   police stations, data centers, traffic lights, etc., across various
   power sectors, which constitutes a system-wide load restoration problem.},
DOI = {10.1109/MPE.2024.3405893},
ISSN = {1540-7977},
EISSN = {1558-4216},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   Pinson, Pierre/GPW-6451-2022
   Wang, Jiawei/HMO-9885-2023
   Pinson, Pierre/C-1601-2009
   Ye, Yujian/AAE-4587-2019},
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089
   Wang, Yi/0000-0002-1280-5418
   Wang, Jiawei/0000-0002-1891-0657
   Pinson, Pierre/0000-0002-1480-0282
   Ye, Yujian/0000-0002-9278-9218},
Unique-ID = {WOS:001362604800017},
}

@article{ WOS:001342822700037,
Author = {Sun, Xiaotian and Xie, Haipeng and Qiu, Dawei and Xiao, Yunpeng and
   Strbac, Goran and Bie, Zhaohong},
Title = {Analytically Quantifying the Efficiency Loss in Competitive Aggregation
   of Demand-Side Resources},
Journal = {IEEE TRANSACTIONS ON SMART GRID},
Year = {2024},
Volume = {15},
Number = {6},
Pages = {6171-6174},
Month = {NOV},
Abstract = {Aggregation of demand-side resources (DSRs) to load aggregators (LAs) is
   a prevailing way to participate in the electricity market. This letter
   proposes an analytical approach to quantify the efficiency loss inherent
   in the competitive aggregation of DSRs by calculating the price of
   anarchy (PoA) via linear programming (LP). First, the equivalent Nash
   equilibrium condition for competitive aggregation is derived. Then, the
   LP problem for PoA calculation is formulated by leveraging
   parameterization and dual reformulation. Finally, applications on a
   demonstrative case and a series of large-scale cases are conducted to
   validate the effectiveness and scalability of the proposed method.},
DOI = {10.1109/TSG.2024.3437654},
ISSN = {1949-3053},
EISSN = {1949-3061},
ResearcherID-Numbers = {Sun, Xiaotian/GSO-1850-2022
   Xie, Haipeng/HNP-8356-2023
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218
   Xiao, Yunpeng/0000-0002-8498-2886
   Qiu, Dawei/0000-0003-0497-6089
   Xie, Haipeng/0000-0001-9845-0058
   Sun, Xiaotian/0000-0003-2538-8841},
Unique-ID = {WOS:001342822700037},
}

@article{ WOS:001317694500092,
Author = {Sun, Xiaotian and Xie, Haipeng and Qiu, Dawei and Xiao, Yunpeng and
   Strbac, Goran and Bie, Zhaohong},
Title = {Incentivizing EVs to Provide Frequency Regulation Services by
   Aggregative Game-Based Mechanism},
Journal = {IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY},
Year = {2024},
Volume = {73},
Number = {9},
Pages = {12787-12800},
Month = {SEP},
Abstract = {The proliferation of electric vehicles (EVs) provides a promising
   resource for regulation services to maintain the frequency of power
   systems. However, two major problems hinder its implementation,
   including the inaccuracy of the EV charging model and the overlook of
   varieties in EV ownership. To facilitate real-world implementation, this
   paper tailors a market-based mechanism to incentivize EVs to provide
   frequency regulation services. Firstly, a detailed EV charging model
   considering the battery equivalent circuit and AC-DC conversion loss is
   proposed. The nonconvexities are approximated and convexified with
   accuracy guarantee. Then, based on the self-interest behavior of EVs, a
   non-cooperative game is adopted to model the competition in providing
   frequency regulation service. The aggregative game is used to
   approximate the original non-cooperative game. Thereby, the existence,
   uniqueness, and approximation accuracy of the aggregative equilibrium is
   theoretically proved. Moreover, the rolling look-ahead iterative
   frequency regulation service clearing mechanism for EV parking lot is
   designed based on the decentralized equilibrium searching algorithm of
   the aggregative game. Finally, the effectiveness, computational
   efficiency, and approximation accuracy of the proposed market-based
   mechanism are validated by a series of numerical tests with EV
   populations at 50, 100, 200, 300, 600, and 900.},
DOI = {10.1109/TVT.2024.3396212},
ISSN = {0018-9545},
EISSN = {1939-9359},
ResearcherID-Numbers = {Xie, Haipeng/HNP-8356-2023
   Sun, Xiaotian/GSO-1850-2022
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218
   Xiao, Yunpeng/0000-0002-8498-2886
   Xie, Haipeng/0000-0001-9845-0058
   Qiu, Dawei/0000-0003-0497-6089
   Sun, Xiaotian/0000-0003-2538-8841},
Unique-ID = {WOS:001317694500092},
}

@article{ WOS:001287801700001,
Author = {Wu, Haochi and Qiu, Dawei and Zhang, Liyu and Sun, Mingyang},
Title = {Adaptive multi-agent reinforcement learning for flexible resource
   management in a virtual power plant with dynamic participating
   multi-energy buildings},
Journal = {APPLIED ENERGY},
Year = {2024},
Volume = {374},
Month = {NOV 15},
Abstract = {Multi-building multi-energy virtual power plants (MB-ME-VPPs) show great
   promise for the aggregation and coordination of distributed flexible
   resources across multiple integrated energy buildings to participate in
   electricity markets. However, a significant challenge arises when
   managing the energy of MB-ME-VPPs, especially since buildings can
   dynamically join or depart during the aggregation phase. Traditional
   model- based optimization methods face difficulties in obtaining
   accurate mathematical models of individual buildings, and may also raise
   privacy concerns. In contrast, model-free multi-agent reinforcement
   learning (MARL) methods offer a promising alternative by allowing agents
   to learn their control policies through interactions with their
   environments. Nevertheless, conventional MARL methods are normally
   applied in static multi- agent environments, where the number and
   identity of agents remain fixed and predetermined. Consequently, these
   conventional MARL methods lack the ability to adapt to the dynamic
   behaviors of agents joining or leaving the environment. To this end,
   this paper proposes a novel approach named MAT-Adapt, embedding the
   multi-agent transformer with a parallel adapter module, to address the
   dynamic participation issue in MB-ME-VPP energy management. Firstly, it
   formulates the coordination of building agents as a sequential modeling
   process and leverages the representational capabilities of the attention
   mechanism from the multi- agent transformer technique. Secondly, it
   introduces a parallel adapter module called AdaptMLP to enhance
   adaptability during the dynamic participation phase, efficiently
   reducing the need for extensive fine-tuning of model parameters.
   Simulations on the IEEE 33-bus distributional electricity market with 3
   to 9 multi- energy buildings show the superior performance of our
   proposed MAT-Adapt method in facilitating efficient coordination of
   dynamically participating buildings within the context of the MB-ME-VPP.
   In comparison to the conventional MADDPG and MAPPO methods training from
   scratch, the proposed MAT-Adapt method demonstrates its superior
   adaptability, achieving 0.75-0.91 normalized rewards in new state
   conditions within 5\% of training episodes, while MADDPG and MAPPO can
   only reach 0.11-0.43 within the same timeframe. Furthermore, the
   proposed MAT-Adapt method exhibits its strong generalization performance
   by evaluating the dynamic participation of various building types and
   regions.},
DOI = {10.1016/j.apenergy.2024.123998},
EarlyAccessDate = {AUG 2024},
Article-Number = {123998},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Sun, Mingyang/ABI-8715-2022
   Wu, Haochi/LFT-2406-2024
   },
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001287801700001},
}

@article{ WOS:001252602200023,
Author = {Qiu, Dawei and Dong, Zihang and Wang, Yi and Zhang, Ning and Strbac,
   Goran and Kang, Chongqing},
Title = {Decarbonising the GB Power System via Numerous Electric Vehicle
   Coordination},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2024},
Volume = {39},
Number = {4},
Pages = {5880-5894},
Month = {JUL},
Abstract = {The increasing penetration of renewable energy has promoted fast
   decarbonisation of the GB power system. However, low-carbon transitions
   should be considered from a whole energy system perspective, such as
   through localised vehicle-to-grid (V2G) techniques. Despite the
   potential benefits of utilising decentralised V2G flexibility for
   decarbonisation, the absence of an appropriate incentive mechanism has
   limited its effectiveness. This paper aims at studying the carbon-aware
   electric vehicle (EV) power scheduling problem by introducing a carbon
   emission flow model. The model enables EVs to be cognisant of carbon
   intensity (CI) signals, thereby enabling them to provide carbon
   services. To solve this problem, a novel decentralised control approach
   is proposed to coordinate numerous EVs in a computationally efficient
   manner with privacy perseverance. Case studies on a 14-node GB power
   network with a large population of 556,733 EVs are conducted to validate
   its efficacy in simultaneously maximising the EVs' carbon service
   provision and decarbonising the GB power system by intelligently linking
   local behaviours with global interest. Finally, the proposed control
   approach shows its generalisation performance for various day and season
   scenarios as well as evidence for realising the GB's decarbonisation
   ambitions by 2030 and 2050.},
DOI = {10.1109/TPWRS.2023.3342168},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Kang, Chongqing/A-6601-2016
   Wang, Yi/JED-9446-2023
   Dong, Zihang/AFK-0995-2022
   Ye, Yujian/AAE-4587-2019
   Zhang, Ning/A-3217-2016
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   DONG, ZIHANG/0000-0003-4541-7259
   Ye, Yujian/0000-0002-9278-9218
   Zhang, Ning/0000-0003-0366-4657
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001252602200023},
}

@article{ WOS:001252808400033,
Author = {Qiu, Dawei and Wang, Yi and Ding, Zhaohao and Wang, Yi and Strbac, Goran},
Title = {Graph Reinforcement Learning for Carbon-Aware Electric Vehicles in
   Power-Transport Networks},
Journal = {IEEE TRANSACTIONS ON SMART GRID},
Year = {2024},
Volume = {15},
Number = {4},
Pages = {3919-3935},
Month = {JUL},
Abstract = {Transitioning towards a low-carbon future necessitates massive efforts
   from both the transport and power sectors. Electric vehicles (EVs) have
   emerged as a promising approach to realize this objective, leveraging
   their smart routing strategies and vehicle-to-grid (V2G) techniques.
   Previous studies have addressed various challenges in EV routing and
   scheduling through model-based optimization methods while ignoring the
   system uncertainties and dynamics. This paper focuses on studying the
   carbon-aware EV joint routing and scheduling problem within a coupled
   power-transport network that can enable EV recharging behaviors within
   the transport network while concurrently delivering carbon-intensity
   services within the power network. Specifically, a carbon emission flow
   model is introduced as a mechanism for tracing and calculating the nodal
   carbon intensity signals tailored for EVs to provide their carbon
   services. To solve this problem, we propose a model-free multi-agent
   reinforcement learning method that harnesses graph convolutional
   networks to capture essential network features and employs a
   parameter-sharing framework to learn large-scale control policies. The
   efficacy and scalability of the proposed method in achieving
   cost-effective and low-carbon transitions are verified through case
   studies involving two power-transport networks with 100 and 1,000 EVs,
   respectively.},
DOI = {10.1109/TSG.2024.3359289},
ISSN = {1949-3053},
EISSN = {1949-3061},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   Ding, Zhaohao/AAV-2744-2020
   Wang, Yi/D-5346-2018
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Wang, Yi/0000-0003-1143-0666
   Ye, Yujian/0000-0002-9278-9218
   Wang, Yi/0000-0002-1280-5418
   Qiu, Dawei/0000-0003-0497-6089
   Ding, Zhaohao/0000-0002-7085-260X},
Unique-ID = {WOS:001252808400033},
}

@article{ WOS:001247852500001,
Author = {Kwateng, Yaa S. A. and Qiu, Dawei and Strbac, Goran},
Title = {Incentivising peers in local transactive energy markets: A case study
   for consumers, prosumers and prosumagers},
Journal = {IET SMART GRID},
Year = {2024},
Volume = {7},
Number = {5},
Pages = {672-694},
Month = {OCT},
Abstract = {A decarbonised future grid should couple technological novelty with
   innovative market models to efficiently capture the value of grid-edge
   decarbonised assets. The transactive energy (TE) concept inverts the
   centralised grid model by leveraging the evolution of consumers to
   prosumers to prosumagers. The principal TE market design challenge is
   transactive control-using market and pricing mechanisms to coordinate
   autonomous peer interactions, to optimally allocate power and
   incentivise peers. Peer attraction, incentivisation and retention are
   all critical for practical TE implementation along three adoption
   stages, starting from independent peer transactions with the centralised
   market; to decentralised peer coordination; towards distributed
   peer-to-peer trading. Addressing gaps in related scholarship, the
   authors investigate the economic positions of distinct peer roles in
   each adoption stage and two local pricing strategies. Using a real
   market dataset, trading decisions are simulated over a 1-year horizon at
   hourly granularity. Coordinated action achieves better transactive
   control for the community, with economic superiority over centralised
   and distributed mechanisms. Distinct peer incentives should equitably
   align with their contribution to market functionality, such as the value
   ascribed to prosumagers' flexibility in local pricing and the
   constrained bargaining power of prosumers in distributed bilateral
   negotiations.
   Addressing gaps in related scholarship, the authors use a case study
   approach to quantify the economic outcomes of distinct peer evolutionary
   roles (consumers, prosumers, and prosumagers) as they participate in the
   market designs (centralised, decentralised, and distributed
   peer-to-peer) along the transactive energy maturity roadmap.
   Decentralised coordinated action is economically superior for the
   community, over centralised and distributed mechanisms. However,
   distinct peer incentives should equitably align with their contribution
   to market functionality, such as the value ascribed to prosumagers'
   flexibility in local prices and the constrained bargaining power of
   prosumers in distributed bilateral negotiations. image},
DOI = {10.1049/stg2.12166},
EarlyAccessDate = {JUN 2024},
EISSN = {2515-2947},
ORCID-Numbers = {Kwateng, Yaa Serwaah/0009-0004-2952-9714},
Unique-ID = {WOS:001247852500001},
}

@article{ WOS:001194520300040,
Author = {Wang, Yi and Qiu, Dawei and Sun, Xiaotian and Bie, Zhaohong and Strbac,
   Goran},
Title = {Coordinating Multi-Energy Microgrids for Integrated Energy System
   Resilience: A Multi-Task Learning Approach},
Journal = {IEEE TRANSACTIONS ON SUSTAINABLE ENERGY},
Year = {2024},
Volume = {15},
Number = {2},
Pages = {920-937},
Month = {APR},
Abstract = {High-impact and low-probability events have occurred more frequently
   than before, which can seriously damage energy supply infrastructures.
   As localized small energy systems, multi-energy microgrids (MEMGs) can
   provide a viable solution for the system-wise load restoration of
   integrated energy systems (IESs), due to their enhanced flexibility and
   controllability. However, existing literature tends to realize MEMGs as
   corrective response rather than load restoration resource after extreme
   events, which cannot fully exploit the benefits of multi-MEMGs on IES
   resilience. This article introduces a decentralized operating paradigm
   for the real-time coordination of local multi-MEMGs towards system-wise
   IES load restoration, while a novel topology-aware multi-task
   reinforcement learning method with soft modularization is proposed to
   solve it. The multi-task learning framework enables MEMGs to
   simultaneously learn scheduling decisions across different network
   topologies and better adapt to unanticipated contingencies.
   Additionally, to avoid insecure MEMG operations, a physics-informed
   safety layer is embedded on top of the multi-task learning framework for
   action corrections. Case studies have been conducted on two IESs (33-bus
   power, 20-node gas, and 20-node heat network as well as 69-bus power,
   40-node gas, and 62-node heat network) to evaluate the effectiveness of
   the proposed method in enabling effective coordination among multi-MEMGs
   towards system-wise IES load restoration.},
DOI = {10.1109/TSTE.2023.3317133},
ISSN = {1949-3029},
EISSN = {1949-3037},
ResearcherID-Numbers = {Sun, Xiaotian/GSO-1850-2022
   Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Sun, Xiaotian/0000-0003-2538-8841
   Qiu, Dawei/0000-0003-0497-6089
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:001194520300040},
}

@article{ WOS:001216033200001,
Author = {Ruan, Guangchun and Qiu, Dawei and Sivaranjani, S. and Awad, Ahmed S. A.
   and Strbac, Goran},
Title = {Data-driven energy management of virtual power plants: A review},
Journal = {ADVANCES IN APPLIED ENERGY},
Year = {2024},
Volume = {14},
Month = {JUL},
Abstract = {A virtual power plant (VPP) refers to an active aggregator of
   heterogeneous distributed energy resources (DERs), which creates a
   promising pathway to expand renewable energy and demand-side
   electrification for deep decarbonization. The VPP market is projected to
   have a significant growth potential, with the global investment surging
   from \$6.47 billion in 2022 to \$16.90 billion by 2030. Up to now, VPPs
   still face technical challenges in dealing with the inherent uncertainty
   of DERs, and data emerge as a promising and essential resource to handle
   this issue. This paper makes the first effort to review the development
   of VPP technologies from a data-centric perspective, and then analyze
   the major role of data within every decision phase of VPPs. We examine
   the VPP energy management through a data lifecycle lens, and extensively
   survey the progress in data creation, data communication, data-driven
   decision support, data sharing and privacy, as well as technical
   solutions stemming from reinforcement learning, peer-to-peer sharing,
   blockchain, and market participation. In addition, we offer a unique
   overview of open data and recent real-world projects around the world to
   showcase the latest VPP practices. We finally discuss the major
   challenges and future opportunities in detail, with a focus on topics
   such as public benchmarks, internet of things, 5G, explainable
   artificial intelligence, and federated learning. We highlight the need
   for technical advances in data management and support systems for the
   growing scale of future VPP systems, and suggest VPPs delivering more
   ancillary grid services in the future.},
DOI = {10.1016/j.adapen.2024.100170},
EarlyAccessDate = {MAR 2024},
Article-Number = {100170},
ISSN = {2666-7924},
ResearcherID-Numbers = {Ruan, Guangchun (Grant)/AAX-5127-2020
   Awad, Ahmed/AAH-7099-2019
   },
ORCID-Numbers = {Ruan, Guangchun (Grant)/0000-0003-2660-9298},
Unique-ID = {WOS:001216033200001},
}

@article{ WOS:001177135800074,
Author = {Qiu, Dawei and Wang, Yi and Wang, Jianhong and Zhang, Ning and Strbac,
   Goran and Kang, Chongqing},
Title = {Resilience-Oriented Coordination of Networked Microgrids: A Shapley
   Q-Value Learning Approach},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2024},
Volume = {39},
Number = {2},
Pages = {3401-3416},
Month = {MAR},
Abstract = {High-impact and low-probability extreme events have occurred more
   frequently than before because of rapid climate change, which can
   seriously damage distribution systems. However, conventional
   distribution management can be dysfunctional after an event, destroying
   its centralized supervision towards resilience enhancement. In this
   context, networked microgrids (NMGs) with distributed energy resources
   provide a viable solution for the resilience enhancement of distribution
   systems. Existing literature tends to employ model-based optimization
   approaches for resilient operations of NMGs, which require complete
   system models and can be time-consuming. To address these challenges,
   this article suggests a decentralized framework for resilience-oriented
   coordination of NMGs and proposes a novel multi-agent reinforcement
   learning (MARL) method to solve it. Specifically, the proposed MARL
   method develops an efficient credit assignment scheme for NMGs to learn
   their contributions to the distribution system resilience via the
   Shapley Q-value technique with more efficient resilience enhancement.
   Case studies based on two modified IEEE 15- and 69-bus distribution
   networks are conducted to validate the effectiveness of the proposed
   MARL method in enabling effective coordination among NMGs and providing
   a high resilience level.},
DOI = {10.1109/TPWRS.2023.3276827},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   Kang, Chongqing/A-6601-2016
   Zhang, Ning/A-3217-2016
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Zhang, Ning/0000-0003-0366-4657
   Ye, Yujian/0000-0002-9278-9218
   Qiu, Dawei/0000-0003-0497-6089
   Wang, Jianhong/0000-0002-7375-8387},
Unique-ID = {WOS:001177135800074},
}

@article{ WOS:001197579500001,
Author = {Qiu, Dawei and Baig, Aimon Mirza and Wang, Yi and Wang, Lingling and
   Jiang, Chuanwen and Strbac, Goran},
Title = {Market design for ancillary service provisions of inertia and frequency
   response via virtual power plants: A non-convex bi-level optimisation
   approach},
Journal = {APPLIED ENERGY},
Year = {2024},
Volume = {361},
Month = {MAY 1},
Abstract = {The Great Britain (GB) government is paving the path to decarbonisation
   by actively promoting the integration of wind power into its generation
   mix. This sharp transition to renewable energy, however, introduces
   specific challenges. The characteristics of non -synchronous wind
   turbines have the potential to impact grid stability and frequency
   security due to the reduction in system inertia. In response to these
   challenges, the deployment of virtual power plants (VPPs) is envisioned
   in deregulated power systems, which allow for the aggregation and
   coordinated control of diverse distributed energy resources, enhancing
   grid flexibility, reliability, and efficiency. Moreover, VPPs offer the
   provision of system inertia and frequency response services at the
   national level. This study drops this assumption and leverages the
   localised flexibility inherent in VPPs to meet the ancillary service
   requirements of the low -carbon power system. The formulated problem is
   constructed as a non -convex bi-level optimisation problem, where the
   upper -level problem represents the operation of a frequency
   -constrained unit commitment model, and the lower -level problem
   embodies the energy dispatches and frequency responses of a group of
   VPPs, guided by the dual price signals of cleared energy and ancillary
   services. To address the non -convex nature of the unit commitment
   problem, a two -fold approach is employed. First, binary commitment
   status decision variables are relaxed to continuous versions.
   Subsequently, the duality gap between the original non -convex unit
   commitment problem and its relaxed dual form is minimised, yielding a
   solution closely approximating the optimal solution of the original
   problem. Second, the relaxed bi-level optimisation problem is
   transformed into a single -level mathematical programs with equilibrium
   constraints by replacing the lower -level VPP problems with their
   equivalent Karush-Kuhn-Tucker optimality conditions. The case studies
   conducted in this work encompass a comprehensive scope. Initially, the
   study evaluates the effectiveness of VPPs in delivering ancillary
   services within the projected context of the GB power system for 2030.
   The findings reveal a substantial 28.28\% decrease in system operation
   costs when compared to the benchmark case lacking VPP flexibility.
   Additionally, the integration of VPPs leads to significantly lower price
   signals for inertia, primary frequency response, and enhanced frequency
   response, reduced by 81.21\%, 79.13\%, and 86.27\%, respectively, in
   contrast to the benchmark case. The analysis then delves into a
   sensitivity exploration, investigating the inherent flexibility of VPPs.
   The profit of local VPPs is expected to increase with VPP flexibility.
   Finally, the study illustrates how VPPs can adapt to and derive benefits
   from an increasing level of wind power penetration by providing a higher
   amount of frequency response.},
DOI = {10.1016/j.apenergy.2024.122929},
EarlyAccessDate = {FEB 2024},
Article-Number = {122929},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   WANG, Lingling/ABH-9973-2020
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Mirza Baig, Aimon/0000-0003-0722-2813
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001197579500001},
}

@inproceedings{ WOS:001345803902046,
Author = {Sun, Xiaotian and Xie, Haipeng and Bie, Zhaohong and Qiu, Dawei and
   Strbac, Goran},
Book-Group-Author = {IEEE},
Title = {Competitive Aggregation of Electric Vehicles for Emergency Supply:
   Model, Equilibrium, and Efficiency Loss},
Booktitle = {2024 IEEE POWER \& ENERGY SOCIETY GENERAL MEETING, PESGM 2024},
Series = {IEEE Power and Energy Society General Meeting PESGM},
Year = {2024},
Note = {IEEE-Power-and-Energy-Society General Meeting (PESGM), Seattle, WA, JUL
   21-25, 2024},
Organization = {IEEE Power \& Energy Soc},
Abstract = {The proliferation of electric vehicles (EVs) has introduced a promising
   resource for relieving power deficits during emergencies. However, the
   dispatch-based management for numerous EVs faces challenges stemming
   from the lack of incentives for EVs and the ignorance of the
   self-serving behavior of load-serving entities (LSEs) in satisfying
   their own demand. To bridge this gap, this paper proposes a two-part
   payment mechanism as an incentive approach for vehicle-to-grid (V2G)
   contributions and conducts an analysis of competition among LSEs for EV
   aggregation. Leveraging cost function reformulation, the competitive
   aggregation is formulated as a non-cooperative game. The concept of
   generalized smoothness condition is introduced to quantify the
   efficiency loss incurred by the competition. This condition is then
   interpreted into an optimization problem, which, through
   parameterization and equivalent reformulation, transforms into a
   tractable linear programming problem capable of analytically competitive
   efficiency loss computation. The scalability and computation efficiency
   of the proposed method are validated in case studies, shedding lights on
   its applicability for policy designers to control the efficiency loss in
   EV aggregation for emergency supply.},
DOI = {10.1109/PESGM51994.2024.10689008},
ISSN = {1944-9925},
ISBN = {979-8-3503-8184-9; 979-8-3503-8183-2},
ResearcherID-Numbers = {Xie, Haipeng/HNP-8356-2023
   Sun, Xiaotian/GSO-1850-2022},
Unique-ID = {WOS:001345803902046},
}

@inproceedings{ WOS:001345803900173,
Author = {Sun, Xiaotian and Xie, Haipeng and Xiao, Yunpeng and Bie, Zhaohong and
   Qiu, Dawei and Strbac, Goran},
Book-Group-Author = {IEEE},
Title = {On the Impact of Coal Supply Chain Disruption to the Electricity Market},
Booktitle = {2024 IEEE POWER \& ENERGY SOCIETY GENERAL MEETING, PESGM 2024},
Series = {IEEE Power and Energy Society General Meeting PESGM},
Year = {2024},
Note = {IEEE-Power-and-Energy-Society General Meeting (PESGM), Seattle, WA, JUL
   21-25, 2024},
Organization = {IEEE Power \& Energy Soc},
Abstract = {Coal supply plays an essential role in the power systems, given the
   prevalence of coal-fired generation facilities. As a consequence,
   disruptions in the coal supply chain, possibly stemming from coal mine
   outages and transportation network interruptions, may strongly affect
   the operation of the electricity market. To address this issue, this
   paper proposes a two-stage simulation framework to assess the
   repercussions of coal supply chain disruptions on the electricity
   market. In the first stage, coal mining enterprises (CMEs) are modelled
   as competitive entities engaged in optimizing their strategies related
   to coal production, transportation, and sales. Variational inequality
   (VI) theory is employed to establish the existence and uniqueness of the
   generalized Nash equilibrium. Then, a decentralized projection-based
   algorithm is proposed based on the equivalently reformulated VI to
   identify the equilibrium in the coal supply chain. The second stage
   focuses on the electricity market clearing process, which hinges on the
   generation cost and the capacity of generation companies (GenCos). These
   attributes are influenced by the equilibrium state of the coal supply
   chain. The effectiveness of the proposed two-stage simulation framework
   in quantifying the impact of coal supply chain disruptions on the
   electricity market is substantiated through validation by an N-1
   disruption simulation conducted on the test system.},
DOI = {10.1109/PESGM51994.2024.10688601},
ISSN = {1944-9925},
ISBN = {979-8-3503-8184-9; 979-8-3503-8183-2},
ResearcherID-Numbers = {Xie, Haipeng/HNP-8356-2023
   Sun, Xiaotian/GSO-1850-2022},
Unique-ID = {WOS:001345803900173},
}

@article{ WOS:001136086900102,
Author = {Wang, Yi and Qiu, Dawei and Teng, Fei and Strbac, Goran},
Title = {Towards Microgrid Resilience Enhancement via Mobile Power Sources and
   Repair Crews: A Multi-Agent Reinforcement Learning Approach},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2024},
Volume = {39},
Number = {1},
Pages = {1329-1345},
Month = {JAN},
Abstract = {Mobile power sources (MPSs) have been gradually deployed in microgrids
   as critical resources to coordinate with repair crews (RCs) towards
   resilience enhancement owing to their flexibility and mobility in
   handling the complex coupled power-transport systems. However, previous
   work solves the coordinated dispatch problem of MPSs and RCs in a
   centralized manner with the assumption that the communication network is
   still fully functioning after the event. However, there is growing
   evidence that certain extreme events will damage or degrade
   communication infrastructure, which makes centralized decision making
   impractical. To fill this gap, this paper formulates the
   resilience-driven dispatch problem of MPSs and RCs in a decentralized
   framework. To solve this problem, a hierarchical multi-agent
   reinforcement learning method featuring a two-level framework is
   proposed, where the high-level action is used to switch decision-making
   between power and transport networks, and the low-level action
   constructed via a hybrid policy is used to compute continuous scheduling
   and discrete routing decisions in power and transport networks,
   respectively. The proposed method also uses an embedded function
   encapsulating system dynamics to enhance learning stability and
   scalability. Case studies based on IEEE 33-bus and 69-bus power networks
   are conducted to validate the effectiveness of the proposed method in
   load restoration.},
DOI = {10.1109/TPWRS.2023.3240479},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001136086900102},
}

@article{ WOS:001136086900143,
Author = {Wang, Yi and Qiu, Dawei and Wang, Yu and Sun, Mingyang and Strbac, Goran},
Title = {Graph Learning-Based Voltage Regulation in Distribution Networks With
   Multi-Microgrids},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2024},
Volume = {39},
Number = {1},
Pages = {1881-1895},
Month = {JAN},
Abstract = {Microgrids (MGs), as localized small power systems, can effectively
   provide voltage regulation services for distribution networks by
   integrating and managing various distributed energy resources. Existing
   literature employs model-based optimization approaches to formulate the
   voltage regulation problem of multi-MGs, which require complete system
   models. However, this assumption is normally impractical due to
   time-varying environment and privacy issues. To fill this research gap,
   this paper suggests a data-driven decentralized framework for the
   cost-effective voltage regulation of a distribution network with
   multi-MGs. A novel multi-agent reinforcement learning method featuring
   an augmented graph convolutional network and a proximal policy
   optimization algorithm is proposed to solve this problem. Furthermore,
   the techniques of critical bus and electrical distance enhance the
   capability of feature extractions from the distribution network,
   allowing for the decentralized training with privacy preserving.
   Simulation results based on modified IEEE 33-bus, 69-bus, and 123-bus
   networks are developed to validate the effectiveness of the proposed
   method in enabling multi-MGs to provide distribution network voltage
   regulation.},
DOI = {10.1109/TPWRS.2023.3242715},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Sun, Mingyang/ABI-8715-2022
   Wang, Yu/T-8812-2019
   Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001136086900143},
}

@article{ WOS:001100325200007,
Author = {Zhang, Tingqi and Sun, Mingyang and Qiu, Dawei and Zhang, Xi and Strbac,
   Goran and Kang, Chongqing},
Title = {A Bayesian Deep Reinforcement Learning-Based Resilient Control for
   Multi-Energy Micro-Gird},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2023},
Volume = {38},
Number = {6},
Pages = {5057-5072},
Month = {NOV},
Abstract = {Aiming at a cleaner future power system, many regimes in the world have
   proposed their ambitious decarbonizing plan, with increasing penetration
   of renewable energy sources (RES) playing an alternative role to
   conventional energy. As a result, power system tends to have less backup
   capacity and operate near their designed limit, thus exacerbating system
   vulnerability against extreme events. Under this reality, resilient
   control for the multi-energy micro-grid is facing the following
   challenges, which are: 1) the effect from the stochastic uncertainties
   of RES; 2) the need for a model-free and fast-reacting control scheme
   under extreme events; and 3) efficient exploration and robust
   performance with limited extreme events data. To deal with the
   aforementioned challenges, this paper proposes a novel Bayesian Deep
   Reinforcement Learning-based resilient control approach for multi-energy
   micro-grid. In particular, the proposed approach replaces the
   deterministic network in traditional Reinforcement Learning with a
   Bayesian probabilistic network in order to obtain an approximation of
   the value function distribution, which effectively solves the Q-value
   overestimation issue. Compared with the naive Deep Deterministic Policy
   Gradient (DDPG) method and optimization method, the effectiveness and
   importance of employing the Bayesian Reinforcement Learning approach are
   investigated and illustrated across different operating scenarios. Case
   studies have shown that by using the Monte Carlo posterior mean of the
   Bayesian value function distribution instead of a deterministic
   estimation, the proposed Bayesian Deep Deterministic Policy Gradient
   (BDDPG) method achieves a near-optimum policy in a more stable process,
   which verifies the robustness and the practicability of the proposed
   approach.},
DOI = {10.1109/TPWRS.2023.3233992},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Zhang, Tingqi/MZS-3284-2025
   Kang, Chongqing/A-6601-2016
   Zhang, Xi/ADI-7558-2022
   Sun, Mingyang/ABI-8715-2022
   },
ORCID-Numbers = {ZHANG, XI/0000-0003-4568-8745
   Qiu, Dawei/0000-0003-0497-6089
   Zhang, Tingqi/0000-0002-6121-3435},
Unique-ID = {WOS:001100325200007},
}

@article{ WOS:001096347100001,
Author = {Wang, Yi and Qiu, Dawei and He, Yinglong and Zhou, Quan and Strbac,
   Goran},
Title = {Multi-agent reinforcement learning for electric vehicle decarbonized
   routing and scheduling},
Journal = {ENERGY},
Year = {2023},
Volume = {284},
Month = {DEC 1},
Abstract = {Low-carbon transitions require joint efforts from electricity grid and
   transport network, where electric vehicles (EVs) play a key role.
   Particularly, EVs can reduce the carbon emissions of transport networks
   through eco-routing while providing the carbon intensity service for
   power networks via vehicle-to-grid technique. Distinguishing from
   previous research that focused on EV routing and scheduling problems
   separately, this paper studies their coordinated effect with the
   objective of carbon emission reduction on both sides. To solve this
   problem, we propose a multi-agent reinforcement learning method that
   does not rely on prior knowledge of the system and can adapt to various
   uncertainties and dynamics. The proposed method learns a hierarchical
   structure for the mutually exclusive discrete routing and continuous
   scheduling decisions via a hybrid policy. Extensive case studies based
   on a virtual 7-node 10-edge transport and 15-bus power network as well
   as a coupled real-world central London transport and 33-bus power
   network are developed to demonstrate the effectiveness of the proposed
   MARL method on reducing carbon emissions in transport network and
   providing carbon intensity service in power network.},
DOI = {10.1016/j.energy.2023.129335},
EarlyAccessDate = {OCT 2023},
Article-Number = {129335},
ISSN = {0360-5442},
EISSN = {1873-6785},
ResearcherID-Numbers = {Zhou, Quan/AAE-2457-2022
   Wang, Yi/JED-9446-2023
   He, Yinglong/ADG-0571-2022
   Zhou, Quan/G-4827-2015
   },
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089
   Zhou, Quan/0000-0003-4216-3468
   Wang, Yi/0000-0002-1280-5418
   He, Yinglong/0000-0002-6666-8471},
Unique-ID = {WOS:001096347100001},
}

@article{ WOS:001085580700001,
Author = {Sun, Xiaotian and Xie, Haipeng and Qiu, Dawei and Xiao, Yunpeng and Bie,
   Zhaohong and Strbac, Goran},
Title = {Decentralized frequency regulation service provision for virtual power A
   best},
Journal = {APPLIED ENERGY},
Year = {2023},
Volume = {352},
Month = {DEC 15},
Abstract = {The high-renewable-penetrated power system frequently requires frequency
   regulation services. By aggregating heterogeneous demand-side flexible
   resources, the virtual power plants (VPP) are able to quickly respond to
   the frequency regulation signal, enabling them promising frequency
   regulation service providers. However, due to the difference in
   ownership, it is unlikely that the self-interested demand-side resources
   are willing to follow the VPP-oriented dispatch results. To bridge this
   gap, this paper proposes a decentralized game-based mechanism for the
   frequency regulation service provision inside the VPP. Firstly, the
   supply function-based bidding models of aggregated demand-side
   resources, namely, demand-side flexible resources and renewable
   distributed generations, are established. Then, a non-cooperative
   generalized Nash game for frequency regulation service provision is
   formulated. The existence, uniqueness, and competitive efficiency loss
   of the game are analyzed by designing an equivalent best response
   potential game of the original game. Additionally, a decentralized
   look-ahead real-time market clearing mechanism for frequency regulation
   service provision inside the VPP is proposed based on dual decomposition
   algorithm. Finally, the effectiveness and computation efficiency of the
   proposed method are validated in the case studies. Meanwhile, it is
   shown that the competition efficiency loss can be effectively reduced
   from around 80\% to 6\% when increasing the demand-side resource
   population from 20 to 2000 as well as balancing the demand-side resource
   composition.},
DOI = {10.1016/j.apenergy.2023.121987},
EarlyAccessDate = {SEP 2023},
Article-Number = {121987},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Sun, Xiaotian/GSO-1850-2022
   Xie, Haipeng/HNP-8356-2023
   },
ORCID-Numbers = {Sun, Xiaotian/0000-0003-2538-8841
   Xiao, Yunpeng/0000-0002-8498-2886
   Xie, Haipeng/0000-0001-9845-0058},
Unique-ID = {WOS:001085580700001},
}

@article{ WOS:001054600200065,
Author = {Qiu, Dawei and Wang, Jianhong and Dong, Zihang and Wang, Yi and Strbac,
   Goran},
Title = {Mean-Field Multi-Agent Reinforcement Learning for Peer-to-Peer
   Multi-Energy Trading},
Journal = {IEEE TRANSACTIONS ON POWER SYSTEMS},
Year = {2023},
Volume = {38},
Number = {5},
Pages = {4853-4866},
Month = {SEP},
Abstract = {With increasing numbers of prosumers employed with multi-energy systems
   (MES) towards higher energy utilization efficiency, an advanced energy
   management scheme is becoming increasingly important. The incorporation
   of MES into the existential energy market holds promise for future power
   systems. The continuous double auction (CDA) market, in a decentralized
   manner, makes it ideal for enabling peer-to-peer (P2P) energy trading
   due to its high transparency and efficiency. However, the CDA market is
   difficult to model when considering the highly stochastic and dynamic
   behaviors of market participants. For this reason, we formulate this
   task as a Decentralized Partially Observed Markov Decision Process and
   propose a novel multi-agent reinforcement learning method that allows
   each prosumer agent to stabilize the training performance with
   mean-field approximation and also to maintain the scalability and
   privacy with market public information. Case studies constructed on a
   real-world scenario of 100 prosumers show that our method captures the
   economic benefits of the P2P energy trading paradigm without violating
   the prosumers' privacy, and outperforms the state-of-the-art methods in
   terms of policy performance, scalability, and computational performance.},
DOI = {10.1109/TPWRS.2022.3217922},
ISSN = {0885-8950},
EISSN = {1558-0679},
ResearcherID-Numbers = {Dong, Zihang/AFK-0995-2022
   Wang, Yi/D-5346-2018
   },
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089
   Wang, Yi/0000-0003-1143-0666
   DONG, ZIHANG/0000-0003-4541-7259},
Unique-ID = {WOS:001054600200065},
}

@article{ WOS:001039358500001,
Author = {Qiu, Dawei and Wang, Yi and Wang, Junkai and Jiang, Chuanwen and Strbac,
   Goran},
Title = {Personalized retail pricing design for smart metering consumers in
   electricity market},
Journal = {APPLIED ENERGY},
Year = {2023},
Volume = {348},
Month = {OCT 15},
Abstract = {In the current deregulated electricity market, flexible consumers are
   more active in participating in market activities via the representation
   of electricity retailers. However, without an effective communication
   infras-tructure, the connection between retailers and the consumers they
   serve is incomplete. Nowadays, smart meters are being rolled out
   worldwide to enhance the connection and data exchanges between retailers
   and consumers. Specifically, smart meters enable retailers to provide
   customers with detailed information about retail tariffs and their
   energy usage at different times of the day, which in turn enables
   customers to manage their energy use more proactively. This paper drops
   this assumption and makes use of data acquired from smart meters to
   design a personalized retail pricing scheme for different types of
   consumers. To formulate this problem, a bi-level optimization model is
   proposed, with the upper-level problem representing the pricing decision
   made by the retailer and two lower-level problems representing the
   demand response of consumers and the wholesale market clearing process,
   respectively. Afterward, we convert this bi-level optimization model
   into a single-level mathematical program with equilibrium constraints by
   using its Karush Kuhn Tucker optimality conditions and complementary
   conditions. The scope of the examined case studies is fourfold. First,
   consumers are classified based on their daily load profiles using the
   advanced clustering method. Second, the physical benefit of fully
   exploring the consumer's demand flexibility as well as the economic
   benefits of increasing retailers' profitability and reducing consumers'
   energy bills are evaluated with respect to the traditional uniform
   retail pricing scheme. Third, the impacts of consumers' demand
   flexibility on electricity market outcomes and business cases are
   investigated. Finally, the proposed personalized retail pricing scheme
   is verified to relieve the strategic retailer's market power reduction
   caused by the flexibility of demand, which is beneficial to the
   retailer's profitability.},
DOI = {10.1016/j.apenergy.2023.121545},
EarlyAccessDate = {JUL 2023},
Article-Number = {121545},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Wang, Junkai/GQY-5392-2022
   Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:001039358500001},
}

@article{ WOS:000967075500001,
Author = {Qiu, Dawei and Chen, Tianyi and Strbac, Goran and Bu, Shengrong},
Title = {Coordination for Multienergy Microgrids Using Multiagent Reinforcement
   Learning},
Journal = {IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS},
Year = {2023},
Volume = {19},
Number = {4},
Pages = {5689-5700},
Month = {APR},
Abstract = {Multienergy microgrids (MEMGs) have significant potential to offer high
   energy utilization efficiency and system flexibility. The coordination
   of these MEMGs poses challenges due to the various system dynamics and
   uncertainties and the need to preserve privacy. This article proposes a
   double auction (DA)-market-based coordination framework. As such, MEMGs
   can not only schedule their own energy components but also trade energy
   with others in the DA market. After that, we formulate this problem as
   Markov games and propose a multiagent reinforcement learning method by
   making use of the DA market public information to enhance the stability
   with privacy perseverance. Case studies involving a real-world scenario
   validate the superior performance of the proposed method in reducing
   both the energy costs and the carbon emissions.},
DOI = {10.1109/TII.2022.3168319},
ISSN = {1551-3203},
EISSN = {1941-0050},
ORCID-Numbers = {Chen, Tianyi/0000-0002-6493-1803
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:000967075500001},
}

@article{ WOS:000993235000001,
Author = {Qiu, Dawei and Wang, Yi and Zhang, Tingqi and Sun, Mingyang and Strbac,
   Goran},
Title = {Hierarchical multi-agent reinforcement learning for repair crews
   dispatch control towards multi-energy microgrid resilience},
Journal = {APPLIED ENERGY},
Year = {2023},
Volume = {336},
Month = {APR 15},
Abstract = {Extreme events are greatly impacting the normal operations of
   microgrids, which can lead to severe outages and affect the continuous
   supply of energy to customers, incurring substantial restoration costs.
   Repair crews (RCs) are regarded as crucial resources to provide system
   resilience owing to their mobility and flexibility characteristics in
   handling both transportation and energy systems. Nevertheless,
   effectively coordinating the dispatch of RCs towards system resilience
   is a complex decision-making problem, especially in the context of a
   multi-energy microgrid (MEMG) with enormous dynamics and uncertainties.
   To this end, this paper formulates the dispatch problem of RCs in a
   coupled transportation and power-gas network as a decentralized
   partially observable Markov decision process (Dec-POMDP). To solve this
   Dec-POMDP, a hierarchical multi -agent reinforcement learning (MARL)
   algorithm is proposed by featuring a two-level framework, where the
   high-level action is used for switching decision-making between
   transportation and power-gas networks, and the lower-level action
   constructed via the multi-agent proximal policy optimization (MAPPO)
   algorithm is used to compute the routing and repairing decisions of RCs
   in the transportation and power-gas networks, respectively. The proposed
   algorithm also introduces an abstracted critic network by integrating
   the load restoration status, which captures the system dynamics and
   stabilizes the training performance with privacy protection. Extensive
   case studies are evaluated on a coupled 6-bus power and 6-bus gas
   network integrated with a 9-node 12-edge transportation network. The
   proposed algorithm outperforms the conventional MARL algorithms in terms
   of policy quality, learning stability, and computational performance.
   Furthermore, the dispatch strategies of RCs are analyzed and their
   corresponding benefits for load restoration are also evaluated. Finally,
   the scalability of the proposed method is also investigated for a larger
   33-bus power and 15-bus gas network integrated with an 18-node 27-edge
   transportation network.},
DOI = {10.1016/j.apenergy.2023.120826},
EarlyAccessDate = {FEB 2023},
Article-Number = {120826},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Zhang, Tingqi/MZS-3284-2025
   Wang, Yi/JED-9446-2023
   Sun, Mingyang/AAL-5144-2020
   },
ORCID-Numbers = {Zhang, Tingqi/0000-0002-6121-3435
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:000993235000001},
}

@article{ WOS:000926964700047,
Author = {Wang, Yi and Qiu, Dawei and Strbac, Goran and Gao, Zhiwei},
Title = {Coordinated Electric Vehicle Active and Reactive Power Control for
   Active Distribution Networks},
Journal = {IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS},
Year = {2023},
Volume = {19},
Number = {2},
Pages = {1611-1622},
Month = {FEB},
Abstract = {The deployment of renewable energy in power systems may raise serious
   voltage instabilities. Electric vehicles (EVs), owing to their mobility
   and flexibility characteristics, can provide various ancillary services
   including active and reactive power. However, the distributed control of
   EVs under such scenarios is a complex decision-making problem with
   enormous dynamics and uncertainties. Most existing literature employs
   model-based approaches to formulate active and reactive power control
   problems, which require full models and are time-consuming. This article
   proposes a multiagent reinforcement learning algorithm featuring a deep
   deterministic policy gradient (DDPG) method and a parameter sharing
   framework to solve the EVs' coordinated active and reactive power
   control problem toward both demand-side response and voltage
   regulations. The proposed algorithm can further enhance the learning
   stability and scalability with privacy perseverance via the location
   marginal prices. Simulation results based on a modified IEEE 15-bus
   network are developed to validate its effectiveness in providing system
   charging and voltage regulation services. The proposed location marginal
   price (LMP) PSDDPG algorithm is evaluated to achieve 38\%, 16\%, and
   25\% speedup, and 1.58, 0.69, and 0.27 times higher reward over the
   benchmarks DDPG, TD3, and LMP-DDPG, respectively.},
DOI = {10.1109/TII.2022.3169975},
ISSN = {1551-3203},
EISSN = {1941-0050},
ResearcherID-Numbers = {Gao, Zhiwei/AAQ-7508-2020
   Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Gao, Zhiwei/0000-0001-5464-3288
   Qiu, Dawei/0000-0003-0497-6089
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:000926964700047},
}

@article{ WOS:000927379300001,
Author = {Wang, Yi and Qiu, Dawei and Sun, Mingyang and Strbac, Goran and Gao,
   Zhiwei},
Title = {Secure energy management of multi-energy microgrid: A physical-informed
   safe reinforcement learning approach},
Journal = {APPLIED ENERGY},
Year = {2023},
Volume = {335},
Month = {APR 1},
Abstract = {The large-scale integration of distributed energy resources into the
   energy industry enables the fast transition to a decarbonized future but
   raises some potential challenges of insecure and unreliable operations.
   Multi-energy Microgrids (MEMGs), as localized small multi-energy
   systems, can effectively integrate a variety of energy components with
   multiple energy sectors, which have been recently recognized as a valid
   solution to improve the operational security and reliability. As a
   result, a massive amount of research has been conducted to investigate
   MEMG energy management problems, including both model-based optimization
   and model-free learning approaches. Compared to optimization approaches,
   reinforcement learning is being widely deployed in MEMG energy
   management problems owing to its ability to handle highly dynamic and
   stochastic processes without knowing any system knowledge. However, it
   is still difficult for conventional model-free reinforcement learning
   methods to capture the physical constraints of the MEMG model, which may
   therefore destroy its secure operation. To address this research
   challenge, this paper proposes a novel safe reinforcement learning
   method by learning a dynamic security assessment rule to abstract a
   physical-informed safety layer on top of the conventional model-free
   reinforcement learning energy management policy, which can respect all
   the physical constraints through mathematically solving an action
   correction formulation. In this setting, the secure energy management of
   the MEMG can be guaranteed for both training and test procedures.
   Extensive case studies based on two integrated systems (i.e., a small
   6-bus power and 7-node gas network, and a large 33-bus power and 20-node
   gas network) are carried out to verify the superior performance of the
   proposed physical-informed reinforcement learning method in achieving a
   cost-effective MEMG energy management performance while respecting all
   the physical constraints, compared to conventional reinforcement
   learning and optimization approaches.},
DOI = {10.1016/j.apenergy.2023.120759},
EarlyAccessDate = {JAN 2023},
Article-Number = {120759},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Sun, Mingyang/AAL-5144-2020
   Gao, Zhiwei/AAQ-7508-2020
   Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Gao, Zhiwei/0000-0001-5464-3288
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:000927379300001},
}

@inproceedings{ WOS:001032836700083,
Author = {Qiu, Dawei and Chrysanthopoulos, Nikolaos and Strbac, Goran},
Book-Group-Author = {IEEE},
Title = {Tariff Design for Local Energy Communities Through Strategic Retail
   Pricing},
Booktitle = {2023 19TH INTERNATIONAL CONFERENCE ON THE EUROPEAN ENERGY MARKET, EEM},
Series = {International Conference on the European Energy Market},
Year = {2023},
Note = {19th International Conference on the European Energy Market (EEM),
   Lappeenranta, FINLAND, JUN 06-08, 2023},
Organization = {IEEE; LUT Univ},
Abstract = {Local energy markets (LEM) have recently attracted great interest as
   they enable effective coordination of small-scale distributed energy
   resources (DER) at the customer side and avoidance of distribution
   network reinforcements. However, the introduction of LEM has also
   significant implications on the strategic interactions between the
   customers and incumbent electricity suppliers. This paper explores these
   interactions by utilising a novel multi-period bi-level optimisation
   problem, which captures the pricing decisions of a strategic supplier
   and the response of energy communities (flexible consumers,
   micro-generators, energy storage systems) either individually or after
   being integrated through a LEM. Case studies are carried out to
   demonstrate the benefits of LEM in both physical and economic terms,
   while the effects on the tariff's design are explored through the
   analysis of supplier's pricing strategies.},
DOI = {10.1109/EEM58374.2023.10161888},
Article-Number = {486},
ISSN = {2165-4077},
ISBN = {979-8-3503-1258-4},
ORCID-Numbers = {Chrysanthopoulos, Nikolaos/0000-0001-9330-1002},
Unique-ID = {WOS:001032836700083},
}

@inproceedings{ WOS:001084633401050,
Author = {Wang, Jiawei and Qiu, Dawei and Wang, Yi and Ghosh, Saptarshi and
   Pinson, Pierre and Dudley, Sandra and Strbac, Goran},
Book-Group-Author = {IEEE},
Title = {Cost-effective and Resilient Operation of Distribution Grids and 5G
   Telecommunication},
Booktitle = {2023 IEEE POWER \& ENERGY SOCIETY GENERAL MEETING, PESGM},
Series = {IEEE Power and Energy Society General Meeting PESGM},
Year = {2023},
Note = {IEEE-Power-and-Energy-Society General Meeting (PESGM), Orlando, FL, JUL
   16-20, 2023},
Organization = {IEEE Power \& Energy Soc},
Abstract = {5G base stations have growing importance in an integrated electric power
   and telecommunication system, for mobile user equipment mobile data
   supply and demand response in distribution grids. However, demand
   response through base station's flexibility can have a growing impact on
   the power flow of the grid. Additionally, in extreme events, if a power
   outage occurs at the physical base station, data loads need to be first
   reconnected to the 5G network, which is essential for the grid to
   further recover the electricity loads. In this paper, a cost-effective
   and resilient operation method is proposed to optimally utilize the
   flexibility of renewable -based 5G base stations and the data load
   shedding to recover the data transmission. The flexibility from
   batteries equipped in the base stations and the flexible associations
   between user equipments and base stations are considered. The simulation
   results verify the proposed method can achieve lower energy costs and
   power losses of the grid in normal operation and a resilient operation
   in an extreme event.},
DOI = {10.1109/PESGM52003.2023.10252696},
ISSN = {1944-9925},
ISBN = {978-1-6654-6441-3},
ResearcherID-Numbers = {Pinson, Pierre/GPW-6451-2022
   Wang, Yi/JED-9446-2023
   Wang, Jiawei/HMO-9885-2023
   Pinson, Pierre/C-1601-2009
   },
ORCID-Numbers = {Wang, Jiawei/0000-0002-1891-0657
   Pinson, Pierre/0000-0002-1480-0282
   Dudley-McEvoy, Sandra/0000-0002-6431-5357},
Unique-ID = {WOS:001084633401050},
}

@inproceedings{ WOS:001032836700084,
Author = {Wang, Junkai and Qiu, Dawei and Strbac, Goran and Ye, Yujian},
Book-Group-Author = {IEEE},
Title = {Market-Based Generation Planning with Carbon Target},
Booktitle = {2023 19TH INTERNATIONAL CONFERENCE ON THE EUROPEAN ENERGY MARKET, EEM},
Series = {International Conference on the European Energy Market},
Year = {2023},
Note = {19th International Conference on the European Energy Market (EEM),
   Lappeenranta, FINLAND, JUN 06-08, 2023},
Organization = {IEEE; LUT Univ},
Abstract = {In the era of the deregulated electricity market, the necessity and
   urgency for reducing carbon emissions are broadly recognized, which
   further drives the market-based generation planning towards a low-carbon
   transition. In this context, this paper proposes a multi-period bi-level
   optimization problem, where the upper-level problem indicates the
   generation company pursuing maximized profit and the lower-level problem
   depicts the market clearing process with carbon limitations. To solve
   it, this bi-level optimization problem is first replaced with its
   mathematical program with equilibrium constraints (MPEC) model and then
   transformed into a mixed integer linear program (MILP) with
   Karush-Kuhn-Tucker (KKT) optimality conditions and strong duality
   theory. Case studies are carried out to evaluate the impact of carbon
   targets on market-based generation investment decisions and business
   cases.},
DOI = {10.1109/EEM58374.2023.10161889},
Article-Number = {435},
ISSN = {2165-4077},
ISBN = {979-8-3503-1258-4},
ResearcherID-Numbers = {Wang, Junkai/GQY-5392-2022
   Ye, Yujian/AAE-4587-2019},
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218},
Unique-ID = {WOS:001032836700084},
}

@article{ WOS:000913015300001,
Author = {Qiu, Dawei and Xue, Juxing and Zhang, Tingqi and Wang, Jianhong and Sun,
   Mingyang},
Title = {Federated reinforcement learning for smart building joint peer-to-peer
   energy and carbon allowance trading},
Journal = {APPLIED ENERGY},
Year = {2023},
Volume = {333},
Month = {MAR 1},
Abstract = {The multi-energy system (MES), which is regarded as an optimum solution
   to a high-efficiency, green energy system and a crucial shift towards
   the future low-carbon energy system, has attracted great attention at
   the district building level. However, the current exploration of
   flexible MES operation has been hampered by (1) the increasing
   penetration of renewable energies and the complicated operation of
   coupling multi-energy sectors; (2) the privacy concern in the
   decentralization of the energy system; and (3) the lack of integration
   of the energy market and carbon emission trading scheme. To address the
   aforementioned challenges, this paper proposes a joint peer-to-peer
   energy and carbon allowance trading mechanism for a building community,
   and then models it as a multi-agent reinforcement learning (MARL)
   paradigm. In this setting, the flexibility of building local trading and
   the decarbonization of building energy management can both be fully
   utilized. To stabilize the training performance, an abstract critic
   network capturing system dynamics is introduced based on a deep
   deterministic policy gradient method. The technique of federated
   learning (FL) is also applied to speed up the training and safeguard the
   private information of each building in the community. Empirical results
   on a real-world test case evaluate its superior performance in terms of
   achieving both economic and environmental benefits, resulting in 5.87\%
   and 8.02\% lower total energy and environment costs than the two
   baseline mechanisms of peer-to-grid energy trading and peer-to-peer
   energy trading, respectively.},
DOI = {10.1016/j.apenergy.2022.120526},
EarlyAccessDate = {DEC 2022},
Article-Number = {120526},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Sun, Mingyang/ABI-8715-2022
   Zhang, Tingqi/MZS-3284-2025
   },
ORCID-Numbers = {Zhang, Tingqi/0000-0002-6121-3435
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:000913015300001},
}

@article{ WOS:000913224500005,
Author = {Qiu, Dawei and Wang, Yi and Hua, Weiqi and Strbac, Goran},
Title = {Reinforcement learning for electric vehicle applications in power
   systems: A critical review},
Journal = {RENEWABLE \& SUSTAINABLE ENERGY REVIEWS},
Year = {2023},
Volume = {173},
Month = {MAR},
Abstract = {Electric vehicles (EVs) are playing an important role in power systems
   due to their significant mobility and flexibility features. Nowadays,
   the increasing penetration of renewable energy resources has been
   observed in modern power systems, which brings many benefits for
   improving climate change and accelerating the low -carbon transition.
   However, the intermittent and unstable nature of renewable energy
   sources introduces new challenges to both the planning and operation of
   power systems. To address these issues, vehicle-to-grid (V2G) technology
   has been gradually recognized as a valid solution to provide various
   ancillary service provisions for power systems. Many studies have
   developed model-based optimization methods for EV dispatch problems.
   Nevertheless, this type of method cannot effectively handle the highly
   dynamic and stochastic environment due to the complexity of power
   systems. Reinforcement learning (RL), a model-free and online learning
   method, can capture various uncertainties through numerous interactions
   with the environment and adapt to various state conditions in real-time.
   As a result, using advanced RL algorithms to solve various EV dispatch
   problems has attracted a surge of attention in recent years, leading to
   many outstanding research papers and important findings. This paper
   provides a comprehensive review of popular RL algorithms categorized by
   single-agent RL and multi-agent RL, and summarizes how these advanced
   algorithms can be applied to various EV dispatch problems, including
   grid-to-vehicle (G2V), vehicle-to-home (V2H), and V2G. Finally, key
   challenges and important future research directions are discussed, which
   involve five aspects: (a) data quality and availability; (b) environment
   setup; (c) safety and robustness; (d) training performance; and (e)
   real-world deployment.},
DOI = {10.1016/j.rser.2022.113052},
EarlyAccessDate = {NOV 2022},
ISSN = {1364-0321},
EISSN = {1879-0690},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Hua, Weiqi/0000-0002-6616-6797
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:000913224500005},
}

@article{ WOS:000856145200089,
Author = {Qiu, Dawei and Wang, Yi and Zhang, Tingqi and Sun, Mingyang and Strbac,
   Goran},
Title = {Hybrid Multiagent Reinforcement Learning for Electric Vehicle Resilience
   Control Towards a Low-Carbon Transition},
Journal = {IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS},
Year = {2022},
Volume = {18},
Number = {11},
Pages = {8258-8269},
Month = {NOV},
Abstract = {In responseto low-carbon requirements, a large amount of renewable
   energy resources (RESs) have been deployed in power systems;
   nevertheless, the intermittency of RESs raises the system vulnerability
   and even causes severe damage under extreme events. Electric vehicles
   (EVs), owing to their mobility and flexibility characteristics, can
   provide various ancillary services meanwhile enhancing system
   resilience. The distributed control of EVs under such scenarios in
   power-transportation network becomes a complex decision-making problem
   with enormous dynamics and uncertainties. To this end, a multiagent
   reinforcement learning method is proposed to compute both discrete and
   continuous actions simultaneously that aligns with the nature of EV
   routing and scheduling problems. Furthermore, the proposed method can
   enhance the learning stability and scalability with privacy perseverance
   in the multiagent setting. Simulation results based on IEEE 6- and
   33-bus power networks integrated with transportation systems validate
   its effectiveness in providing system resilience and carbon intensity
   service.},
DOI = {10.1109/TII.2022.3166215},
ISSN = {1551-3203},
EISSN = {1941-0050},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   Zhang, Tingqi/MZS-3284-2025
   Sun, Mingyang/ABI-8715-2022
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418
   Qiu, Dawei/0000-0003-0497-6089
   Zhang, Tingqi/0000-0002-6121-3435},
Unique-ID = {WOS:000856145200089},
}

@article{ WOS:001022700700004,
Author = {Qiu, Dawei and Dong, Zihang and Ruan, Guangchun and Zhong, Haiwang and
   Strbac, Goran and Kang, Chongqing},
Title = {Strategic retail pricing and demand bidding of retailers in electricity
   market: A data-driven chance-constrained programming},
Journal = {ADVANCES IN APPLIED ENERGY},
Year = {2022},
Volume = {7},
Month = {SEP},
Abstract = {This paper proposes a novel bi-level optimization model to study the
   strategic retail pricing and demand bidding problems of an electricity
   retailer that considers the interactions between demand response and
   market clearing process. In order to accurately forecast the day-ahead
   demand bids submitted by the retailer, a novel deep learning framework
   based on convolutional neural networks and long short-term memory is
   proposed that can capture both local trends and long-term dependency of
   the forecasting data. In addition, uncertainties about the retailer's
   served demand, rivals' demand bids, and wind power generation are
   incorporated using the data-driven uncertainty set constructed from
   data. We further propose chance-constrained programming that introduces
   a set of chance constraints to represent the operational risk associated
   with the market uncertainties. To solve this problem, we first
   reformulate chance-constrained programming as a tractable second-order
   conic programming and then convert it into a single-level mathematical
   program with equilibrium constraints by using its Karush Kuhn Tucker
   conditions. The scope of the examined case studies is four-fold. First,
   they evaluate the benefits of the proposed forecasting framework in
   terms of higher accuracy and expected profit compared to the
   conventional forecasting methods. Second, they demonstrate how demand
   flexibility affects the retailer's strategies and its business cases.
   Third, they highlight the added value of the proposed bi-level model
   capturing the market clearing process by comparing its outcomes against
   the state-of-the-art bi-level model with exogenous market prices.
   Finally, they analyze the retailer's strategies and business cases at
   different confidence levels regarding the imposed chance constraints.},
DOI = {10.1016/j.adapen.2022.100100},
Article-Number = {100100},
ISSN = {2666-7924},
ResearcherID-Numbers = {Dong, Zihang/AFK-0995-2022
   Kang, Chongqing/A-6601-2016
   Ruan, Guangchun (Grant)/AAX-5127-2020
   Zhong, Haiwang/A-6492-2016
   },
ORCID-Numbers = {DONG, ZIHANG/0000-0003-4541-7259
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:001022700700004},
}

@article{ WOS:000859460400006,
Author = {Zeng, Lanting and Qiu, Dawei and Sun, Mingyang},
Title = {Resilience enhancement of multi-agent reinforcement learning-based
   demand response against adversarial attacks},
Journal = {APPLIED ENERGY},
Year = {2022},
Volume = {324},
Month = {OCT 15},
Abstract = {Demand response improves grid security by adjusting the flexibility of
   consumers meanwhile maintaining their demand-supply balance in
   real-time. With the large-scale deployment of distributed digital
   communication technologies and advanced metering infrastructures,
   data-driven approaches such as multi-agent reinforcement learning (MARL)
   are being widely employed to solve demand response problems.
   Nevertheless, the massive interaction of data inside and outside the
   demand response management system may lead to severe threats from the
   perspective of cyber-attacks. The cyber security requirements of
   MARL-based demand response problems are less discussed in the existing
   studies. To this end, this paper proposes a robust adversarial
   multi-agent reinforcement learning framework for demand response
   (RAMARL-DR) with an enhanced resilience against adversarial attacks. In
   particular, the proposed RAMARL-DR first constructs an adversary agent
   that aims to cause the worst-case performance via formulating an
   adversarial attack; and then adopts periodic alternating robust
   adversarial training scenarios with the optimal adversary aiming to
   diminish the severe impacts induced by adversarial attacks. Case studies
   are conducted based on an OpenAI Gym environment CityLearn, which
   provides a standard evaluation platform of MARL algorithms for demand
   response problems. Empirical results indicate that the MARL-based demand
   response management system is vulnerable when the adversary agent
   occurs, and its performance can be significantly improved after periodic
   alternating robust adversarial training. It can be found that the
   adversary agent can result in a 41.43\% higher metric value of Ramping
   than the no adversary case, whereas the proposed RAMARL-DR can
   significantly enhance the system resilience with an approximately
   38.85\% reduction in the ramping of net demand.},
DOI = {10.1016/j.apenergy.2022.119688},
EarlyAccessDate = {AUG 2022},
Article-Number = {119688},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Sun, Mingyang/ABI-8715-2022
   },
ORCID-Numbers = {ceng, lan ting/0000-0003-0605-0490},
Unique-ID = {WOS:000859460400006},
}

@article{ WOS:000782815700001,
Author = {Bellizio, Federica and Xu, Wangkun and Qiu, Dawei and Ye, Yujian and
   Papadaskalopoulos, Dimitrios and Cremer, Jochen L. and Teng, Fei and
   Strbac, Goran},
Title = {Transition to Digitalized Paradigms for Security Control and
   Decentralized Electricity Market},
Journal = {PROCEEDINGS OF THE IEEE},
Year = {2023},
Volume = {111},
Number = {7},
Pages = {744-761},
Month = {JUL},
Abstract = {Digitalization is one of the key drivers for energy system
   transformation. The advances in communication technologies and
   measurement devices render available a large amount of operational data
   and enable the centralization of such data storage and processing. The
   greater access to data opens up new opportunities for a more efficient
   and decentralized management of the energy system. At the distribution
   level of the energy system, local electricity markets (LEMs) provide new
   degrees of flexibility by trading and balancing the energy locally and
   offering ancillary services to the wider transmission and distribution
   system operators. Maximizing the grid impact from this flexibility calls
   for novel data analytics and artificial intelligence techniques to
   enhance the system's security and reduce the energy costs of local
   prosumers. At the same time, however, relying on data-based approaches
   increases the risk of cyberattacks, and robust countermeasures are,
   therefore, needed as an integral aspect of digitalization efforts. This
   article discusses the key role of centralized data analytics to fully
   benefit from the advantages of LEMs in terms of system's security
   enhancement and energy costs' reduction. Data-driven paradigms are
   investigated that allow for flexibility from decentralized markets,
   mitigate the physical security risks, and devise defensive strategies
   shielding the system from cyber threats.},
DOI = {10.1109/JPROC.2022.3161053},
EarlyAccessDate = {APR 2022},
ISSN = {0018-9219},
EISSN = {1558-2256},
ResearcherID-Numbers = {teng, fei/HNI-1377-2023
   Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Bellizio, Federica/0000-0002-7351-1704
   Ye, Yujian/0000-0002-9278-9218
   Qiu, Dawei/0000-0003-0497-6089
   Papadaskalopoulos, Dimitrios/0000-0002-7064-3429
   Cremer, Jochen Lorenz/0000-0001-9284-5083
   Xu, Wangkun/0000-0001-9811-2673},
Unique-ID = {WOS:000782815700001},
}

@article{ WOS:000797533700009,
Author = {Qiu, Dawei and Wang, Yi and Sun, Mingyang and Strbac, Goran},
Title = {Multi-service provision for electric vehicles in power-transportation
   networks towards a low-carbon transition: A hierarchical and hybrid
   multi-agent reinforcement learning approach},
Journal = {APPLIED ENERGY},
Year = {2022},
Volume = {313},
Month = {MAY 1},
Abstract = {In order to achieve the target of carbon peak and carbon neutrality,
   electric vehicles (EVs) have increasingly received a prominent interest
   to electrify the transportation sector due to their advantages of
   mobility and flexibility on handling complicated transportation and
   power networks. However, it is still challenging to realize the
   significant potential of EVs towards an emerging low-carbon transition.
   Previous works have focused on vehicle-to-grid (V2G) technology that
   allows for an increased utilization of EVs to make arbitrage by the
   temporal differentials of electricity prices. Nevertheless, the economic
   potential of EVs flexibility may not be fully exploited lacking an
   appropriate business model. This paper addresses this challenge by
   developing a coupled power-transportation network for cooperative EVs to
   optimize the provision of multiple inter-dependent services, including
   charging service, demand management service, carbon intensity service,
   and balancing service. In order to unlock this value, the EVs operation
   problem has already been tackled using model-based optimization
   approaches, which may raise privacy issues since the requirement for
   global information and also can be time consuming due to the high
   variability of transportation and power networks. In this paper, we
   propose a model-free hierarchical and hybrid multi-agent reinforcement
   learning method to learn the routing and scheduling decisions of EVs in
   a coupled power-transportation network with the objective of optimizing
   multi-service provisions. To this end, EVs do not reply on any knowledge
   of the simulated environment and are capable of handling system
   uncertainties via the learning process. Extensive case studies based on
   a 15-bus radial power distribution network and a 9-node 12-edge
   transportation network are developed to show that the proposed method
   outperforms the conventional learning algorithms in terms of policy
   quality and convergence speed. Finally, the generalizability and
   scalability are also investigated for different environment
   circumstances and EV numbers.},
DOI = {10.1016/j.apenergy.2022.118790},
EarlyAccessDate = {MAR 2022},
Article-Number = {118790},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   Sun, Mingyang/AAL-5144-2020
   },
ORCID-Numbers = {Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:000797533700009},
}

@article{ WOS:000774187200006,
Author = {Wang, Yi and Qiu, Dawei and Strbac, Goran},
Title = {Multi-agent deep reinforcement learning for resilience-driven routing
   and scheduling of mobile energy storage systems},
Journal = {APPLIED ENERGY},
Year = {2022},
Volume = {310},
Month = {MAR 15},
Abstract = {Extreme events are featured by high impact and low probability, which
   can cause severe damage to power systems. There has been much research
   focused on resilience-driven operational problems incorporating mobile
   energy storage systems (MESSs) routing and scheduling due to its
   mobility and flexibility. However, existing literature focuses on
   model-based optimization approaches to implement the routing process of
   MESSs, which can be time consuming and raise privacy issues since the
   requirement for global information of both power and transportation
   networks. Furthermore, a real-time automatic control scheme of MESSs has
   become a challenging task due to the system high variability. As such,
   this paper develops a model-free real-time multi agent deep
   reinforcement learning approach featuring parameterized double deep
   Q-networks to reformulate the coordination effect of MESSs routing and
   scheduling process as a Partially Observable Markov Game, which is
   capable of capturing a hybrid policy including both discrete and
   continuous actions. A coupled transportation network and linearized
   AC-OPF algorithm are realized as the environment, while the internal
   uncertainties associated with renewable energy sources, load profiles,
   line outages, and traffic volumes are incorporated into the proposed
   data-driven approach through learning procedure. Extensive case studies
   including both 6-bus and 33-bus power networks are developed to evaluate
   the effectiveness of the proposed approach. Specifically, a detailed
   comparison between different multi-agent reinforcement learning and
   model-based optimization approaches is conducted to present the superior
   performance of the proposed approach.},
DOI = {10.1016/j.apenergy.2022.118575},
EarlyAccessDate = {FEB 2022},
Article-Number = {118575},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023
   },
ORCID-Numbers = {Qiu, Dawei/0000-0003-0497-6089
   Wang, Yi/0000-0002-1280-5418},
Unique-ID = {WOS:000774187200006},
}

@article{ WOS:000817213100001,
Author = {Qiu, Dawei and Dong, Zihang and Zhang, Xi and Wang, Yi and Strbac, Goran},
Title = {Safe reinforcement learning for real-time automatic control in a smart
   energy-hub},
Journal = {APPLIED ENERGY},
Year = {2022},
Volume = {309},
Month = {MAR 1},
Abstract = {Nowadays, multi-energy systems are receiving special attention from
   smart grid community owing to their high flexibility potentials
   integrating with multiple energy carriers. In this regard, energy hub is
   known as a flexible and efficient platform to supply energy demands with
   an acceptable range of affordability and reliability by relying on
   various energy production, storage and conversion facilities. Given the
   increasing penetration of renewable energy sources to promote a
   low-carbon energy transition, accurate economic and environmental
   assessment of energy hub, along with the real-time automatic energy
   management scheme has become a challenging task due to the high
   variability of renewable energy sources. Furthermore, the conventional
   model-based optimization approach requiring full knowledge of the
   employed mathematical operating models and accurate uncertainty
   distributions may become impractical for real-world applications. In
   this context, this paper proposes a model-free safe deep reinforcement
   learning method for the optimal control of a renewable-based energy hub
   operating in multiple energy carries while satisfying the physical
   constraints within the energy hub operation model. The main objective of
   this work is to minimize the system energy cost and carbon emission by
   considering various energy components. The proposed deep reinforcement
   learning method is trained and tested on a real-world dataset to
   validate its superior performance in reducing energy cost, carbon
   emission, and computational time with respect to the state-of-the-art
   deep reinforcement learning and optimized-based approaches. Moreover,
   the effectiveness of the proposed method in dealing with model operation
   constraints is evaluated on both training and test environments.
   Finally, the generalization performance for the learnt energy management
   scheme as well as the sensitivity analysis on storage flexibility and
   carbon price are also examined in the case studies.},
DOI = {10.1016/j.apenergy.2021.118403},
EarlyAccessDate = {JAN 2022},
Article-Number = {118403},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Zhang, Xi/ADI-7558-2022
   Dong, Zihang/AFK-0995-2022
   Wang, Yi/D-5346-2018
   },
ORCID-Numbers = {ZHANG, XI/0000-0003-4568-8745
   Wang, Yi/0000-0003-1143-0666
   DONG, ZIHANG/0000-0003-4541-7259},
Unique-ID = {WOS:000817213100001},
}

@inproceedings{ WOS:000934720603011,
Author = {Wang, Yi and Qiu, Dawei and Strbac, Goran},
Book-Group-Author = {IEEE},
Title = {Multi-agent reinforcement learning for electric vehicles joint routing
   and scheduling strategies},
Booktitle = {2022 IEEE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION
   SYSTEMS (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2022},
Pages = {3044-3049},
Note = {IEEE 25th International Conference on Intelligent Transportation Systems
   (ITSC), Macau, PEOPLES R CHINA, OCT 08-12, 2022},
Organization = {IEEE},
Abstract = {Transforming to a low-carbon future requires massive efforts from both
   transport and power systems. Electric vehicles (EVs) can reduce CO2
   emission in road transport through eco-routing while providing carbon
   intensity service for power systems via vehicle-to-grid (V2G)
   scheduling. This paper studies the coordinated effect of routing and
   scheduling problems of EVs via a novel model-free multi-agent
   reinforcement learning (MARL) method. In this context, EVs do not reply
   on any knowledge of the simulated environment and are capable of
   handling the system with various uncertainties and dynamics during the
   learning process, which can lead to timely decision making and better
   privacy protection. Extensive case studies based on a virtual 7-node
   10-edge transportation network are developed to demonstrate the
   effectiveness of the proposed MARL method on reducing carbon emissions
   in the transportation system and providing carbon intensity service in
   the power system.},
DOI = {10.1109/ITSC55140.2022.9921744},
ISSN = {2153-0009},
ISBN = {978-1-6654-6880-0},
ResearcherID-Numbers = {Wang, Yi/JED-9446-2023},
Unique-ID = {WOS:000934720603011},
}

@article{ WOS:000647556200003,
Author = {Qiu, Dawei and Ye, Yujian and Papadaskalopoulos, Dimitrios and Strbac,
   Goran},
Title = {Scalable coordinated management of peer-to-peer energy trading: A
   multi-cluster deep reinforcement learning approach},
Journal = {APPLIED ENERGY},
Year = {2021},
Volume = {292},
Month = {JUN 15},
Abstract = {The increasing penetration of small-scale distributed energy resources
   (DER) has the potential to support cost-efficient energy balancing in
   emerging electricity systems, but is also fundamentally affecting the
   conventional operation paradigm of the latter. In this context,
   innovative market mechanisms need to be devised to better coordinate and
   provide incentives for DER to utilize their flexibility. Peer-to-Peer
   (P2P) energy trading has emerged as an alternative approach to
   facilitate direct trading between consumers and prosumers interacting in
   an energy collective and fosters more efficient local demand-supply
   balancing. While previous research has primarily focused on the
   technical and economic benefits of P2P trading, little effort has been
   made towards the incorporation of prosumers' heterogeneous
   characteristics in the P2P trading problem. Here, we address this
   research gap by classifying the participating prosumers into multiple
   clusters with regard to their portfolio of DER, and analyzing their
   trading decisions in a simulated P2P trading platform. The latter
   employs the mid-market rate (MMR) local pricing mechanism to enable
   energy trading among prosumers and penalizes the contribution to the
   system demand peak of each prosumer. We formulate the P2P trading
   problem as a multi-agent coordination problem and propose a novel
   multi-agent deep reinforcement learning (MADRL) method to address it.
   The proposed method is founded on the combination of the multi-agent
   deep deterministic policy gradient (MADDPG) algorithm and the technique
   of parameter sharing (PS), which not only enables accelerating the
   training speed by sharing experiences and learned policies between all
   agents in each cluster, but also sustains the policies' diversity
   between multiple clusters. To address the non-stationarity and
   computational complexity of MADRL as well as persevering the privacy of
   prosumers, the P2P trading platform acts as a trusted third party which
   augments the market collective trading information to help training of
   prosumer agents. Experiments with a large-scale real-world data-set
   involving 300 residential households demonstrate that the proposed MADRL
   method exhibits a strong generalization capability in the test data-set
   and outperforms the state-of-the-art MADRL methods with regard to the
   system operation cost, demand peak as well as computational time.},
DOI = {10.1016/j.apenergy.2021.116940},
EarlyAccessDate = {APR 2021},
Article-Number = {116940},
ISSN = {0306-2619},
EISSN = {1872-9118},
ResearcherID-Numbers = {Ye, Yujian/AAE-4587-2019
   },
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218
   Qiu, Dawei/0000-0003-0497-6089},
Unique-ID = {WOS:000647556200003},
}

@article{ WOS:000615066200001,
Author = {Ye, Yujian and Qiu, Dawei and Wang, Huiyu and Tang, Yi and Strbac, Goran},
Title = {Real-Time Autonomous Residential Demand Response Management Based on
   Twin Delayed Deep Deterministic Policy Gradient Learning},
Journal = {ENERGIES},
Year = {2021},
Volume = {14},
Number = {3},
Month = {FEB},
Abstract = {With the roll-out of smart meters and the increasing prevalence of
   distributed energy resources (DERs) at the residential level, end-users
   rely on home energy management systems (HEMSs) that can harness
   real-time data and employ artificial intelligence techniques to
   optimally manage the operation of different DERs, which are targeted
   toward minimizing the end-user's energy bill. In this respect, the
   performance of the conventional model-based demand response (DR)
   management approach may deteriorate due to the inaccuracy of the
   employed DER operating models and the probabilistic modeling of
   uncertain parameters. To overcome the above drawbacks, this paper
   develops a novel real-time DR management strategy for a residential
   household based on the twin delayed deep deterministic policy gradient
   (TD3) learning approach. This approach is model-free, and thus does not
   rely on knowledge of the distribution of uncertainties or the operating
   models and parameters of the DERs. It also enables learning of
   neural-network-based and fine-grained DR management policies in a
   multi-dimensional action space by exploiting high-dimensional sensory
   data that encapsulate the uncertainties associated with the renewable
   generation, appliances' operating states, utility prices, and outdoor
   temperature. The proposed method is applied to the energy management
   problem for a household with a portfolio of the most prominent types of
   DERs. Case studies involving a real-world scenario are used to validate
   the superior performance of the proposed method in reducing the
   household's energy costs while coping with the multi-source
   uncertainties through comprehensive comparisons with the
   state-of-the-art deep reinforcement learning (DRL) methods.},
DOI = {10.3390/en14030531},
Article-Number = {531},
EISSN = {1996-1073},
ResearcherID-Numbers = {Ye, Yujian/AAE-4587-2019},
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218},
Unique-ID = {WOS:000615066200001},
}

@inproceedings{ WOS:001202335502136,
Author = {Qiu, Dawei and Wang, Jianhong and Wang, Junkai and Strbac, Goran},
Editor = {Zhou, ZH},
Title = {Multi-Agent Reinforcement Learning for Automated Peer-to-Peer Energy
   Trading in Double-Side Auction Market},
Booktitle = {PROCEEDINGS OF THE THIRTIETH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE, IJCAI 2021},
Year = {2021},
Pages = {2913-2920},
Note = {30th International Joint Conference on Artificial Intelligence (IJCAI),
   ELECTR NETWORK, AUG 19-27, 2021},
Organization = {Int Joint Conf Artifical Intelligence},
Abstract = {With increasing prosumers employed with distributed energy resources
   (DER), advanced energy management has become increasingly important. To
   this end, integrating demand-side DER into electricity market is a trend
   for future smart grids. The double-side auction (DA) market is viewed as
   a promising peer-to-peer (P2P) energy trading mechanism that enables
   interactions among prosumers in a distributed manner. To achieve the
   maximum profit in a dynamic electricity market, prosumers act as price
   makers to simultaneously optimize their operations and trading
   strategies. However, the traditional DA market is difficult to be
   explicitly modelled due to its complex clearing algorithm and the
   stochastic bidding behaviors of the participants. For this reason, in
   this paper we model this task as a multi-agent reinforcement learning
   (MARL) problem and propose an algorithm called DA-MADDPG that is
   modified based on MADDPG by abstracting the other agents' observations
   and actions through the DA market public information for each agent's
   critic. The experiments show that 1) prosumers obtain more economic
   benefits in P2P energy trading w.r.t. the conventional electricity
   market independently trading with the utility company; and 2) DA-MADDPG
   performs better than the traditional Zero Intelligence (ZI) strategy and
   the other MARL algorithms, e.g., IQL, ID-DPG, IPPO and MADDPG.},
ISBN = {978-0-9992411-9-6},
ResearcherID-Numbers = {Wang, Junkai/GQY-5392-2022
   },
ORCID-Numbers = {Wang, Jianhong/0000-0002-7375-8387},
Unique-ID = {WOS:001202335502136},
}

@article{ WOS:000594661800004,
Author = {Qiu, Dawei and Ye, Yujian and Papadaskalopoulos, Dimitrios},
Title = {Exploring the effects of local energy markets on electricity retailers
   and customers},
Journal = {ELECTRIC POWER SYSTEMS RESEARCH},
Year = {2020},
Volume = {189},
Month = {DEC},
Abstract = {Local energy markets (LEM) have recently attracted great interest as
   they enable effective coordination of smallscale distributed energy
   resources (DER) at the customer side, and avoidance of distribution
   network reinforcements. However, the introduction of LEM has also
   significant implications on the strategic interactions between the
   customers and incumbent electricity retailers. This paper explores for
   the first time these interactions by proposing a novel multi-period
   bi-level optimization model, which captures the pricing decisions of a
   strategic retailer in the upper level (UL) and the response of both
   independent customers and the LEM (both including flexible consumers,
   micro-generators and energy storages) in the lower level (LL). Since the
   LL problem representing the LEM is non-convex, a new analytical approach
   is employed for solving the developed bilevel problem. The examined case
   studies demonstrate that the introduction of an LEM reduces the
   customers' energy dependency on the retailer and limits the retailer's
   strategic potential of exploiting the customers through large
   differentials between buy and sell prices. As a result, the profit of
   the retailer is significantly reduced while the customers, primarily the
   LEM participants and to a lower extent non-participating customers,
   achieve significant economic benefits.},
DOI = {10.1016/j.epsr.2020.106761},
Article-Number = {106761},
ISSN = {0378-7796},
EISSN = {1873-2046},
ResearcherID-Numbers = {Ye, Yujian/AAE-4587-2019},
ORCID-Numbers = {Ye, Yujian/0000-0002-9278-9218},
Unique-ID = {WOS:000594661800004},
}
